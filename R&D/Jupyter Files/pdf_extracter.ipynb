{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "fe3f8e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pdfplumber\n",
    "import os\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "id": "93173ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory = 'F:/projects/RR/Datasets/sample_resumes/r_resumes/'\n",
    "# sub_diectory = 'F:/projects/RR/Datasets/sample_resumes/r_resumes/text_r_resumes/'\n",
    "# final_directory = 'F:/projects/RR/Datasets/sample_resumes/r_resumes/resumes_final/'\n",
    "\n",
    "directory = 'F:/projects/RR/Datasets/data_folder/pdf_files/'\n",
    "sub_diectory = 'F:/projects/RR/Datasets/data_folder/pdf2txt_files/'\n",
    "final_directory = 'F:/projects/RR/Datasets/data_folder/txt2txt_files/'\n",
    "csv_directory = 'F:/projects/RR/Datasets/data_folder/txt2_csv_files/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "id": "9de8f51a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:/projects/RR/Datasets/data_folder/pdf2txt_files/abinash cv1.txt\n",
      "F:/projects/RR/Datasets/data_folder/pdf2txt_files/AnilSahoo[2_2].txt\n",
      "F:/projects/RR/Datasets/data_folder/pdf2txt_files/AshishBiradar[3_1].txt\n",
      "F:/projects/RR/Datasets/data_folder/pdf2txt_files/ChhattuRoy[6_5] (1).txt\n",
      "F:/projects/RR/Datasets/data_folder/pdf2txt_files/DondetiAnjiReddy[3_2].txt\n",
      "F:/projects/RR/Datasets/data_folder/pdf2txt_files/MAnilKumar[4_3].txt\n",
      "F:/projects/RR/Datasets/data_folder/pdf2txt_files/MullaInayathulla[5_1] (1).txt\n",
      "F:/projects/RR/Datasets/data_folder/pdf2txt_files/NarasimhaReddyBoddapati[3_6].txt\n",
      "F:/projects/RR/Datasets/data_folder/pdf2txt_files/Prashanth.txt\n",
      "F:/projects/RR/Datasets/data_folder/pdf2txt_files/RaghuramB[3_2].txt\n",
      "F:/projects/RR/Datasets/data_folder/pdf2txt_files/Rajesh[4_6]_763240f9-2c79-402c-8624-55e5cc96b8f3.txt\n",
      "F:/projects/RR/Datasets/data_folder/pdf2txt_files/Rini_J_Prabha (1).txt\n",
      "F:/projects/RR/Datasets/data_folder/pdf2txt_files/Rohit_Saini__Bhiwani_3.txt\n",
      "F:/projects/RR/Datasets/data_folder/pdf2txt_files/SampathBukya[3_2].txt\n",
      "F:/projects/RR/Datasets/data_folder/pdf2txt_files/sulochanakamshettey[4_6].txt\n"
     ]
    }
   ],
   "source": [
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.pdf'):\n",
    "        fullpath = os.path.join(directory, filename) \n",
    "        name = fullpath.split('.')\n",
    "        filename = name[0].split('/')\n",
    "#         print(filename[-1])\n",
    "        filename = filename[-1]+\".txt\"\n",
    "        file_path = sub_diectory+filename\n",
    "        print(file_path)\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as fp:\n",
    "            with pdfplumber.open(fullpath) as pdf:\n",
    "                for page in pdf.pages:\n",
    "                    text = page.extract_text()\n",
    "                    fp.write(text)\n",
    "                fp.write(\"\\n\")\n",
    "                fp.write(\"End Of Resume\")\n",
    "                fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ab129d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "email = [\"email id\", \"email\", \"email id:\"]\n",
    "cell = [\"cell\", \"mobile\", \"contact\", \"mobile num\", \"phone\", \"cell:\", \"mobile:\", \"contact:\", \"mobile num:\", \"phone:\", \n",
    "       \"cell\\n\", \"mobile\\n\", \"contact\\n\", \"mobile num\\n\", \"phone\\n\"]\n",
    "linkedin = [\"linkedin\", \"linked in\", \"linkedin:\", \"linked in:\", \"linkedin\\n\", \"linked in\\n\"]\n",
    "# github = [\"github\"]\n",
    "# address = ['address']\n",
    "career_objective = ['career objective', 'career objective:', 'career objective\\n',\n",
    "                    'objective', 'objective:', 'objective\\n']\n",
    "\n",
    "professional_background = ['professional background','professional background:', 'professional background\\n', \n",
    "                           'professional profile', 'professional profile:', 'professional profile\\n',\n",
    "                           'profile summary', 'profile summary:', 'profile summary\\n', \n",
    "                           'summary', 'summary:', 'summary\\n', \n",
    "                           'experience summary', 'experience summary:', 'experience summary\\n', \n",
    "                           'professional summary', 'professional summary:', 'professional summary\\n', \n",
    "                           'profile', 'profile\\n', 'profile:']\n",
    "\n",
    "key_skills = ['key skills', 'key skills:', 'key skills\\n' \n",
    "              'skills', 'skills:', 'skills\\n',\n",
    "              'expertise and skills', 'expertise and skills:', 'expertise and skills\\n']\n",
    "\n",
    "qualification = ['qualification summary', 'qualification summary:', 'qualification summary\\n']\n",
    "\n",
    "technical_skills = ['technical skills', 'technical skills:', 'technical skills\\n']\n",
    "\n",
    "work_experience = ['work experience', 'work experience:', 'work experience\\n' \n",
    "                   'projects', 'projects:', 'projects\\n', \n",
    "                   'research and experience','research and experience:', 'research and experience\\n', \n",
    "                   'experience', 'experience:', 'experience\\n', \n",
    "                   'professional experience' ,'professional experience:', 'professional experience\\n',\n",
    "                   'professional projects','professional projects:', 'professional projects\\n', \n",
    "                   'academic projects','academic projects:', 'academic projects\\n']\n",
    "\n",
    "research = ['other research activities','other research activities:', 'other research activities\\n', \n",
    "            'research papers', 'research papers:', 'research papers\\n']\n",
    "\n",
    "academics = ['academic qualification','academic qualification:', 'academic qualification\\n', \n",
    "             'educational qualification','educational qualification:','educational qualification\\n',\n",
    "              'education','education:', 'education\\n', \n",
    "             'educational profile','educational profile:', 'educational profile\\n', \n",
    "             'academic profile', 'academic profile:', 'academic profile\\n', \n",
    "             'academic qualifications', 'academic qualifications:', 'academic qualifications\\n']\n",
    "\n",
    "personal_details = ['personal details:', 'personal details\\n', 'personal details', 'personal profile','personal profile:', \n",
    "                    'personal profile\\n', 'personal information', 'personal information:', 'personal information\\n']\n",
    "\n",
    "# strength = ['strength', 'strengths']\n",
    "# hobbies = ['hobbies', 'activities']\n",
    "\n",
    "declaration = ['declaration:', 'declaration\\n', 'declaration', 'self-assesment:', 'self-assesment\\n', 'self-assesment']\n",
    "\n",
    "accomplishments = ['accomplishments:', 'accomplishments\\n','accomplishments', 'achievements:', 'achievements\\n', 'achievements']\n",
    "\n",
    "publications = ['publication:', 'publication\\n', 'publication']\n",
    "\n",
    "conference = ['conference and training:', 'conference and training\\n', 'conference and training']\n",
    "\n",
    "references = ['references:', 'references\\n', 'references']\n",
    "# languages = ['languages', 'linguistics']\n",
    "# role = ['role']\n",
    "# designation = ['designation']\n",
    "\n",
    "preffered_location = ['location preference:', 'location preference\\n', 'location preference']\n",
    "\n",
    "certificates = ['certificates:', 'certificates\\n', 'certificates']\n",
    "\n",
    "interests = ['interests:', 'interests\\n', 'interests']\n",
    "\n",
    "key_result_areas = ['key result areas:', 'key result areas\\n', 'key result areas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50399a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "heads = [email, cell, linkedin, career_objective, professional_background, key_skills, qualification,\n",
    "         technical_skills,work_experience, research, academics, personal_details, declaration,\n",
    "        accomplishments, publications, conference, references, preffered_location, certificates, \n",
    "        interests, key_result_areas]\n",
    "\n",
    "all_heddings = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48fee18e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af0714b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in heads:\n",
    "    for j in i:\n",
    "        all_heddings.append(j)\n",
    "# all_heddings\n",
    "len(all_heddings)\n",
    "# res = any(rs_he[i] in rs_he[i] for rs_he[i] in rs_he)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "077f55a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['email id',\n",
       " 'email',\n",
       " 'email id:',\n",
       " 'cell',\n",
       " 'mobile',\n",
       " 'contact',\n",
       " 'mobile num',\n",
       " 'phone',\n",
       " 'cell:',\n",
       " 'mobile:',\n",
       " 'contact:',\n",
       " 'mobile num:',\n",
       " 'phone:',\n",
       " 'cell\\n',\n",
       " 'mobile\\n',\n",
       " 'contact\\n',\n",
       " 'mobile num\\n',\n",
       " 'phone\\n',\n",
       " 'linkedin',\n",
       " 'linked in',\n",
       " 'linkedin:',\n",
       " 'linked in:',\n",
       " 'linkedin\\n',\n",
       " 'linked in\\n',\n",
       " 'career objective',\n",
       " 'career objective:',\n",
       " 'career objective\\n',\n",
       " 'objective',\n",
       " 'objective:',\n",
       " 'objective\\n',\n",
       " 'professional background',\n",
       " 'professional background:',\n",
       " 'professional background\\n',\n",
       " 'professional profile',\n",
       " 'professional profile:',\n",
       " 'professional profile\\n',\n",
       " 'profile summary',\n",
       " 'profile summary:',\n",
       " 'profile summary\\n',\n",
       " 'summary',\n",
       " 'summary:',\n",
       " 'summary\\n',\n",
       " 'experience summary',\n",
       " 'experience summary:',\n",
       " 'experience summary\\n',\n",
       " 'professional summary',\n",
       " 'professional summary:',\n",
       " 'professional summary\\n',\n",
       " 'profile',\n",
       " 'profile\\n',\n",
       " 'profile:',\n",
       " 'key skills',\n",
       " 'key skills:',\n",
       " 'key skills\\nskills',\n",
       " 'skills:',\n",
       " 'skills\\n',\n",
       " 'expertise and skills',\n",
       " 'expertise and skills:',\n",
       " 'expertise and skills\\n',\n",
       " 'qualification summary',\n",
       " 'qualification summary:',\n",
       " 'qualification summary\\n',\n",
       " 'technical skills',\n",
       " 'technical skills:',\n",
       " 'technical skills\\n',\n",
       " 'work experience',\n",
       " 'work experience:',\n",
       " 'work experience\\nprojects',\n",
       " 'projects:',\n",
       " 'projects\\n',\n",
       " 'research and experience',\n",
       " 'research and experience:',\n",
       " 'research and experience\\n',\n",
       " 'experience',\n",
       " 'experience:',\n",
       " 'experience\\n',\n",
       " 'professional experience',\n",
       " 'professional experience:',\n",
       " 'professional experience\\n',\n",
       " 'professional projects',\n",
       " 'professional projects:',\n",
       " 'professional projects\\n',\n",
       " 'academic projects',\n",
       " 'academic projects:',\n",
       " 'academic projects\\n',\n",
       " 'other research activities',\n",
       " 'other research activities:',\n",
       " 'other research activities\\n',\n",
       " 'research papers',\n",
       " 'research papers:',\n",
       " 'research papers\\n',\n",
       " 'academic qualification',\n",
       " 'academic qualification:',\n",
       " 'academic qualification\\n',\n",
       " 'educational qualification',\n",
       " 'educational qualification:',\n",
       " 'educational qualification\\n',\n",
       " 'education',\n",
       " 'education:',\n",
       " 'education\\n',\n",
       " 'educational profile',\n",
       " 'educational profile:',\n",
       " 'educational profile\\n',\n",
       " 'academic profile',\n",
       " 'academic profile:',\n",
       " 'academic profile\\n',\n",
       " 'academic qualifications',\n",
       " 'academic qualifications:',\n",
       " 'academic qualifications\\n',\n",
       " 'personal details:',\n",
       " 'personal details\\n',\n",
       " 'personal details',\n",
       " 'personal profile',\n",
       " 'personal profile:',\n",
       " 'personal profile\\n',\n",
       " 'personal information',\n",
       " 'personal information:',\n",
       " 'personal information\\n',\n",
       " 'declaration:',\n",
       " 'declaration\\n',\n",
       " 'declaration',\n",
       " 'self-assesment:',\n",
       " 'self-assesment\\n',\n",
       " 'self-assesment',\n",
       " 'accomplishments:',\n",
       " 'accomplishments\\n',\n",
       " 'accomplishments',\n",
       " 'achievements:',\n",
       " 'achievements\\n',\n",
       " 'achievements',\n",
       " 'publication:',\n",
       " 'publication\\n',\n",
       " 'publication',\n",
       " 'conference and training:',\n",
       " 'conference and training\\n',\n",
       " 'conference and training',\n",
       " 'references:',\n",
       " 'references\\n',\n",
       " 'references',\n",
       " 'location preference:',\n",
       " 'location preference\\n',\n",
       " 'location preference',\n",
       " 'certificates:',\n",
       " 'certificates\\n',\n",
       " 'certificates',\n",
       " 'interests:',\n",
       " 'interests\\n',\n",
       " 'interests',\n",
       " 'key result areas:',\n",
       " 'key result areas\\n',\n",
       " 'key result areas']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_heddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "id": "850395c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_heddings.append('end of resume')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "id": "a88e2313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_heddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "id": "f4a98c19",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "list1 = []\n",
    "list2 = []\n",
    "list3 = []\n",
    "list4 = []\n",
    "list5 = []\n",
    "\n",
    "file_path = sub_diectory+filename\n",
    "for filename in os.listdir(sub_diectory):\n",
    "    if filename.endswith('.txt'):\n",
    "        fullpath = os.path.join(sub_diectory, filename)\n",
    "        name = fullpath.split('.')\n",
    "        fname = name[0].split('/')\n",
    "        fn = fn[-1]+\".txt\"\n",
    "        file_path = final_directory + fn\n",
    "        txt_file_path = sub_diectory + filename\n",
    "        with open(fullpath, encoding='utf-8') as fp:\n",
    "            text = fp.read()\n",
    "            text = text.lower()\n",
    "\n",
    "            for i in all_heddings:\n",
    "                if i in text:\n",
    "                    out = re.search(i, text)\n",
    "                    list1.append(out.group(0))\n",
    "\n",
    "            # using loop to iterate for each string\n",
    "            list1.sort(key = len)\n",
    "\n",
    "            for idx, val in enumerate(list1):\n",
    "                # concatenating all next values and checking for existence\n",
    "                if val not in ', '.join(list1[idx + 1:]):\n",
    "                    list2.append(val)\n",
    "\n",
    "            for i in list2:\n",
    "                if i in text:\n",
    "                    out = re.search(i, text)\n",
    "                    index = re.search(i, text).start()\n",
    "                    list3.append((out.group(0), index))\n",
    "\n",
    "            list3.sort(key=lambda y:y[1])\n",
    "\n",
    "            for i in range(len(list3)):        \n",
    "                a, b = list3[i]\n",
    "                list4.append(a)  \n",
    "                \n",
    "            for i in range(0, len(list4)-1):\n",
    "                rgx =re.compile(r'(?si)(?|{0}(.*?){1}|{1}(.*?){0})'.format(list4[i], list4[i+1]))\n",
    "                list5.append(list4[i])\n",
    "                m = rgx.findall(text)\n",
    "                for x in m:\n",
    "                    for j in x:\n",
    "                        list5.append(j)\n",
    "        \n",
    "             \n",
    "#             print(fname[-1])\n",
    "            \n",
    "            csv_file = fname[-1]+\".xlsx\"\n",
    "            csv_path = csv_directory+csv_file\n",
    "        \n",
    "            final_dict = {}\n",
    "        \n",
    "            for i in range(0, len(list5)-1, 2):\n",
    "                final_dict[list5[i]] = list5[i+1]\n",
    "            \n",
    "            df = pd.DataFrame(final_dict, index=[0])\n",
    "        \n",
    "            df.to_excel(csv_path)\n",
    "        \n",
    "        with open(file_path,\"w\", encoding='utf-8') as fp:\n",
    "            content = ''.join(list5)\n",
    "            content = content.lower()\n",
    "            content.strip()\n",
    "            fp.write(content)\n",
    "            fp.write(\"\\nend of resume\")\n",
    "            fp.close()\n",
    "            \n",
    "        list1.clear()\n",
    "        list2.clear()\n",
    "        list3.clear()\n",
    "        list4.clear()\n",
    "        list5.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "id": "8b31ddd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(r'F:\\projects\\RR\\Datasets\\data_folder\\txt2_csv_files\\abinash cv1.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "id": "fef94723",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "id": "8b0654f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>email id:</th>\n",
       "      <th>cell:</th>\n",
       "      <th>career objective</th>\n",
       "      <th>key skills</th>\n",
       "      <th>qualification summary</th>\n",
       "      <th>technical skills</th>\n",
       "      <th>work experience</th>\n",
       "      <th>objective:</th>\n",
       "      <th>academic qualifications</th>\n",
       "      <th>personal details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>abinashgcs@gmail.com</td>\n",
       "      <td>+91-7008460530 \\n \\n \\n</td>\n",
       "      <td>\\n \\nhighly motivated individual with a strong track record of performance in handling relationship \\nmanagement activities to identify and define business requirements, and translate business needs \\ninto complex models. competent at identifying different data sources and providing associated data \\nmodelling and data visualization. \\n \\n</td>\n",
       "      <td>\\n \\n| python | advance predictive modeling and designing drilldown analysis for business insights \\n|statistical modeling  |machine learning algorithms| eda | natural language processing |text \\nmining |text class|my sql| credit risk analysis and project management  | client management \\nand cross functional project handling | git  \\n \\n</td>\n",
       "      <td>\\n \\n  analytical, enthusiastic and innovative data science lead with  3+ years of it experience in the \\ndifferent areas of data science, machine learning and automation. \\n  deft at undertaking various statistical methods and testing processes such as hypothesis testing, \\nlinear regression, logistic regression, clustering, decision trees, random forest and natural \\nlanguage processing.  \\n \\n  pragmatic  exposure  in  data  ingestion  and  cleaning  using  python  programming. thorough \\nknowledge of data warehousing and data mining concepts. \\n \\n  sound knowledge of drawing insights through predictive analysis and data visualization, to drive \\nbetter decision making through the use of various statistical modelling techniques.  \\n \\n  experienced in all phases of data analysis spanning definition and analysis of questions with \\nrespect to available dasta &amp; resources, overview of data &amp;  assessment of data quality, selection of \\nappropriate models &amp; statistical tests and presentation of results \\n \\n  leveraging skill in importing, cleaning, transforming, validating or modelling data with the purpose \\nof understanding or making conclusions from the data for decision making purposes. \\n \\n  good at sql commands (ddl, dml, dcl, joins, sub queries) and sql functions. \\n \\n</td>\n",
       "      <td>\\n \\n \\n  python - developed various regression and classification models of ml using pandas, numpy, scikit \\nlearn etc, and visualization using seaborn and matplotlib libraries. good experience in validating \\nmodels using cross validation, confusion matrix, roc curve etc. \\n  statistics- strong understanding on applied statistics and advance statistical analysis.   machine learning and ai– strong working knowledge of various ml regression and classification \\nalgorithms such as linear and logistic regression, decision tree, random forest, svm,knn,naïve-\\nbayes,xg-boost etc. strong knowledge of hypothesis testing. \\n  sql– good knowledge on database management and query writing skills in sql and access. \\nstatements and clauses, entity and attribute relationships, joins, views, pivot and un-pivot, case and \\nwhen statement, ranking and row order and store procedures etc. \\n \\n \\n \\n \\n</td>\n",
       "      <td>\\n  3+ years of experience in sysark datasol pvt. ltd. (jan 2019-till date) \\n \\n \\n mar 2021 till sep 2021 \\n \\nproject : credit risk management \\ndesignation : data scientist  \\ntools &amp; techologies used : python,eda,statistical analysis,machine learning models,cross validation. \\n</td>\n",
       "      <td>\\nthe main objective of this project is to understand credit risk management which is a practice of mitigating \\nlosses by understanding the adequacy of a bank’s capital and loan loss reserves at any given time, a \\nprocess that has long been a challenge for financial institutions. \\neffective credit risk management is to gain a complete understanding of a bank’s overall credit risk by \\nviewing risk at the individual, customer and portfolio levels. \\n \\nresponsibility: \\n  to understand the business problem and interact with the client on regular basis to get more and \\ndeep insight of the data shared by the client. \\n  better model management that spans the entire modelling life cycle. \\n  data visualization capabilities and business intelligence tools that get important information into \\nthe hands of those who need it, when they need it. \\n  to draw the insights from the data and develop a predictive model which will help in categorizing \\nthe individual customer and sector of the bank efficiently. \\n  to do the variable selection which are important in developing predictive model with good \\naccuracy.  \\n  prepare origination and performance reporting to create multiple dashboards for drill down \\nanalysis and specific kpi metrics. \\n  design data architecture and solve complex data integrity issues.  \\n  design various charts to explain the trend and perforce of portfolios over the period of time. \\n  create drill down analysis in tableau. \\n \\n      dec2019-nov 2020 \\nproject :  sentiment analysis \\nsentiment analysis for air purification market: the client in consumer electronics domain was looking \\nfor insights into a fast growing product in indian consumer market – air purifiers. the insights project was \\ndriven by sentiment analysis of social media data  (i.e. tweets /comments / status updates/product \\nreviews) using python. the project also included a paid review classifier which would flag reviews as paid \\nor genuine. \\n  \\nobjective: the main objective of this project is to  determine whether data is positive, negative \\nor neutral. sentiment analysis is often performed on textual data to help businesses monitor \\nbrand and product sentiment in customer feedback, and understand customer needs. \\n \\n \\nproject type: classification model, consumer insights \\nduration: dec 2019-nov 2020 \\ntools used: python, microsoft power point \\ntechniques used: svm linear, document term matrix, lexicon token analysis, n-gram distribution, \\nsentiment polarity scoring \\nrole: project manager/data analyst \\nresponsibilities: \\n  requirement gathering  \\n  project planning and execution  \\n  task allocation \\n  classification modeling \\n  feature engineering \\n  python scripting for natural language processing, classification \\n  power point presentation \\n \\n</td>\n",
       "      <td>\\n \\n \\n  ssc  from shanti niketan high school with a percentage of 78 %. \\n  hsc (+2)  in science(pcm) from lambodar college of science with a percentage of  75 %. \\n  b.tech from kmbb college of engineering and technology with an overall cgpa of 7.01. \\n \\n</td>\n",
       "      <td>\\n \\ndate of birth               :   15th june,1995 \\ngender               :      male \\naddress               :      at-gandhi nagar pada,balangir,odisha,pin-767001 \\nlinguistics               :     english &amp; hindi \\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                             email id:                     cell:  \\\n",
       "0           0  abinashgcs@gmail.com                   +91-7008460530 \\n \\n \\n   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                career objective  \\\n",
       "0   \\n \\nhighly motivated individual with a strong track record of performance in handling relationship \\nmanagement activities to identify and define business requirements, and translate business needs \\ninto complex models. competent at identifying different data sources and providing associated data \\nmodelling and data visualization. \\n \\n                                                                          \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                              key skills  \\\n",
       "0   \\n \\n| python | advance predictive modeling and designing drilldown analysis for business insights \\n|statistical modeling  |machine learning algorithms| eda | natural language processing |text \\nmining |text class|my sql| credit risk analysis and project management  | client management \\nand cross functional project handling | git  \\n \\n   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 qualification summary  \\\n",
       "0   \\n \\n  analytical, enthusiastic and innovative data science lead with  3+ years of it experience in the \\ndifferent areas of data science, machine learning and automation. \\n  deft at undertaking various statistical methods and testing processes such as hypothesis testing, \\nlinear regression, logistic regression, clustering, decision trees, random forest and natural \\nlanguage processing.  \\n \\n  pragmatic  exposure  in  data  ingestion  and  cleaning  using  python  programming. thorough \\nknowledge of data warehousing and data mining concepts. \\n \\n  sound knowledge of drawing insights through predictive analysis and data visualization, to drive \\nbetter decision making through the use of various statistical modelling techniques.  \\n \\n  experienced in all phases of data analysis spanning definition and analysis of questions with \\nrespect to available dasta & resources, overview of data &  assessment of data quality, selection of \\nappropriate models & statistical tests and presentation of results \\n \\n  leveraging skill in importing, cleaning, transforming, validating or modelling data with the purpose \\nof understanding or making conclusions from the data for decision making purposes. \\n \\n  good at sql commands (ddl, dml, dcl, joins, sub queries) and sql functions. \\n \\n   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       technical skills  \\\n",
       "0   \\n \\n \\n  python - developed various regression and classification models of ml using pandas, numpy, scikit \\nlearn etc, and visualization using seaborn and matplotlib libraries. good experience in validating \\nmodels using cross validation, confusion matrix, roc curve etc. \\n  statistics- strong understanding on applied statistics and advance statistical analysis.   machine learning and ai– strong working knowledge of various ml regression and classification \\nalgorithms such as linear and logistic regression, decision tree, random forest, svm,knn,naïve-\\nbayes,xg-boost etc. strong knowledge of hypothesis testing. \\n  sql– good knowledge on database management and query writing skills in sql and access. \\nstatements and clauses, entity and attribute relationships, joins, views, pivot and un-pivot, case and \\nwhen statement, ranking and row order and store procedures etc. \\n \\n \\n \\n \\n   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                 work experience  \\\n",
       "0   \\n  3+ years of experience in sysark datasol pvt. ltd. (jan 2019-till date) \\n \\n \\n mar 2021 till sep 2021 \\n \\nproject : credit risk management \\ndesignation : data scientist  \\ntools & techologies used : python,eda,statistical analysis,machine learning models,cross validation. \\n   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   objective:  \\\n",
       "0   \\nthe main objective of this project is to understand credit risk management which is a practice of mitigating \\nlosses by understanding the adequacy of a bank’s capital and loan loss reserves at any given time, a \\nprocess that has long been a challenge for financial institutions. \\neffective credit risk management is to gain a complete understanding of a bank’s overall credit risk by \\nviewing risk at the individual, customer and portfolio levels. \\n \\nresponsibility: \\n  to understand the business problem and interact with the client on regular basis to get more and \\ndeep insight of the data shared by the client. \\n  better model management that spans the entire modelling life cycle. \\n  data visualization capabilities and business intelligence tools that get important information into \\nthe hands of those who need it, when they need it. \\n  to draw the insights from the data and develop a predictive model which will help in categorizing \\nthe individual customer and sector of the bank efficiently. \\n  to do the variable selection which are important in developing predictive model with good \\naccuracy.  \\n  prepare origination and performance reporting to create multiple dashboards for drill down \\nanalysis and specific kpi metrics. \\n  design data architecture and solve complex data integrity issues.  \\n  design various charts to explain the trend and perforce of portfolios over the period of time. \\n  create drill down analysis in tableau. \\n \\n      dec2019-nov 2020 \\nproject :  sentiment analysis \\nsentiment analysis for air purification market: the client in consumer electronics domain was looking \\nfor insights into a fast growing product in indian consumer market – air purifiers. the insights project was \\ndriven by sentiment analysis of social media data  (i.e. tweets /comments / status updates/product \\nreviews) using python. the project also included a paid review classifier which would flag reviews as paid \\nor genuine. \\n  \\nobjective: the main objective of this project is to  determine whether data is positive, negative \\nor neutral. sentiment analysis is often performed on textual data to help businesses monitor \\nbrand and product sentiment in customer feedback, and understand customer needs. \\n \\n \\nproject type: classification model, consumer insights \\nduration: dec 2019-nov 2020 \\ntools used: python, microsoft power point \\ntechniques used: svm linear, document term matrix, lexicon token analysis, n-gram distribution, \\nsentiment polarity scoring \\nrole: project manager/data analyst \\nresponsibilities: \\n  requirement gathering  \\n  project planning and execution  \\n  task allocation \\n  classification modeling \\n  feature engineering \\n  python scripting for natural language processing, classification \\n  power point presentation \\n \\n   \n",
       "\n",
       "                                                                                                                                                                                                                                                   academic qualifications  \\\n",
       "0   \\n \\n \\n  ssc  from shanti niketan high school with a percentage of 78 %. \\n  hsc (+2)  in science(pcm) from lambodar college of science with a percentage of  75 %. \\n  b.tech from kmbb college of engineering and technology with an overall cgpa of 7.01. \\n \\n   \n",
       "\n",
       "                                                                                                                                                                                                              personal details  \n",
       "0   \\n \\ndate of birth               :   15th june,1995 \\ngender               :      male \\naddress               :      at-gandhi nagar pada,balangir,odisha,pin-767001 \\nlinguistics               :     english & hindi \\n  "
      ]
     },
     "execution_count": 570,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "id": "1d705b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_dict = {}\n",
    "# for i in range(0, len(list5)-1, 2):\n",
    "#     final_dict[list5[i]] = list5[i+1]\n",
    "\n",
    "# df = pd.DataFrame(final_dict, index=[0])\n",
    "\n",
    "# df.to_csv(csv_path+\".csv\", index= [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c17d738",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc9422e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "1420139f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for i in range(0, len(list4)-1):\n",
    "#     print(list4[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "9bc6d5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in res:\n",
    "#     if i in text:\n",
    "#         out = re.search(i, text)\n",
    "# #             hed.append(out.group(0))\n",
    "#         index = re.search(i, text).start()\n",
    "#         hed.append((out.group(0), index))\n",
    "        \n",
    "# hed.sort(key=lambda y:y[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "301808a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_head = []\n",
    "# for i in range(len(hed)): \n",
    "#     a, b = hed[i]\n",
    "#     final_head.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "ee270924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "e51ec4af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "adfc3e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hed = []\n",
    "\n",
    "# with open(\"F:/projects/RR/Datasets/sample_resumes/r_resumes/text_r_resumes/DondetiAnjiReddy[3_2].txt\", encoding='utf-8') as fp:\n",
    "#     text = fp.read()\n",
    "#     text = text.lower()\n",
    "    \n",
    "#     for i in all_heddings:\n",
    "#         if i in text:\n",
    "#             out = re.search(i, text)\n",
    "# #             hed.append(out.group(0))\n",
    "#             index = re.search(i, text).start()\n",
    "#             hed.append((out.group(0), index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "001d51be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "id": "05044994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hed.sort(key=lambda y:y[1])\n",
    "# hed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cc2c1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "b0e4775e",
   "metadata": {},
   "source": [
    "# k = []\n",
    "# for i in range(len(hed)):\n",
    "#     a, b = hed[i]\n",
    "#     k.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "id": "4d0ba1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list1 = []\n",
    "# list2 = []\n",
    "# list3 = []\n",
    "# final_list = []\n",
    "\n",
    "# with open(\"F:/projects/RR/Datasets/sample_resumes/r_resumes/text_r_resumes/abinash cv1.txt\", encoding='utf-8') as fp:\n",
    "#     text = fp.read()\n",
    "#     text = text.lower()\n",
    "    \n",
    "#     for i in all_heddings:\n",
    "#         if i in text:\n",
    "#             out = re.search(i, text) \n",
    "#             list1.append(out.group(0))\n",
    "\n",
    "#     # using loop to iterate for each string\n",
    "#     list1.sort(key = len)\n",
    "\n",
    "#     for idx, val in enumerate(list1):\n",
    "#         # concatenating all next values and checking for existence\n",
    "#         if val not in ', '.join(list1[idx + 1:]):\n",
    "#             list2.append(val)\n",
    "            \n",
    "#     for i in list2:\n",
    "#         if i in text:\n",
    "#             out = re.search(i, text)\n",
    "#             index = re.search(i, text).start()\n",
    "#             list3.append((out.group(0), index))\n",
    "            \n",
    "#     list3.sort(key=lambda y:y[1])\n",
    "    \n",
    "#     for i in range(len(list3)):        \n",
    "#         a, b = list3[i]\n",
    "#         final_list.append(a)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "id": "388fcc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for filename in os.listdir(sub_diectory):\n",
    "#     if filename.endswith('.txt'):\n",
    "#         fullpath = os.path.join(sub_diectory, filename)\n",
    "# #         name = fullpath.split('.')\n",
    "# #         fn = name[0].split('/')\n",
    "# #         fn = fn[-1]+\".txt\"\n",
    "# #         file_path = final_directory + fn\n",
    "# #         txt_file_path = sub_diectory + filename\n",
    "#         with open(fullpath, encoding='utf-8') as fp:\n",
    "#             text = fp.read()\n",
    "#             text = text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "id": "505ac734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "a894f396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# h = [\"Email ID:\", \"Cell:\", \"Career Objective\", \"Key Skills\", \"Qualification Summary\", \"Technical Skills\", \"Work Experience\", \"Academic Qualifications\", \"Personal Details\" , \"End Of Resume\"]\n",
    "\n",
    "# data = \"\"\n",
    "# p = []\n",
    "# file_path = sub_diectory+filename\n",
    "# for filename in os.listdir(sub_diectory):\n",
    "#     if filename.endswith('.txt'):\n",
    "#         fullpath = os.path.join(sub_diectory, filename)\n",
    "#         name = fullpath.split('.')\n",
    "#         fn = name[0].split('/')\n",
    "#         fn = fn[-1]+\".txt\"\n",
    "#         file_path = final_directory + fn\n",
    "#         txt_file_path = sub_diectory + filename\n",
    "#         with open(txt_file_path,\"r\", encoding=\"utf-8\" ) as fp:\n",
    "#             text = fp.read().replace(\"\\n\", \"\")\n",
    "#             for i in range(0, len(h)-1):                \n",
    "#                 rgx =re.compile(r'(?si)(?|{0}(.*?){1}|{1}(.*?){0})'.format(h[i], h[i+1]))\n",
    "#                 p.append(h[i])\n",
    "#                 m = rgx.findall(text)\n",
    "#                 for x in m:\n",
    "#                     for j in x:\n",
    "#                         p.append(j)\n",
    "#         with open(file_path,\"w\", encoding='utf-8') as fp:\n",
    "#             finalString = '\\n'.join(p)\n",
    "#             finalString = finalString.lower()\n",
    "#             finalString.strip()\n",
    "#             fp.write(finalString)\n",
    "#             fp.write(\"\\nend of resume\")\n",
    "#             fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94139e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
