{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.2.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'F:\\\\projects\\\\ARP'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "from pathlib import Path\n",
    "import spacy\n",
    "import re\n",
    "import spacy_lookups_data\n",
    "\n",
    "import random\n",
    "from spacy.util import minibatch,compounding\n",
    "from spacy.tokens import Doc\n",
    "from spacy.training import Example\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 9)\n"
     ]
    }
   ],
   "source": [
    "json_data = pd.read_json('./Datasets/chunk_data/output/PS_50.json')\n",
    "print(json_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json_data = pd.read_json('F:\\basic.json').iloc[0:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json_data = pd.read_json('F:/basic.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>annotations</th>\n",
       "      <th>predictions</th>\n",
       "      <th>file_upload</th>\n",
       "      <th>data</th>\n",
       "      <th>meta</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>project</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>172</td>\n",
       "      <td>[{'id': 62, 'completed_by': {'id': 1, 'email':...</td>\n",
       "      <td>[]</td>\n",
       "      <td>04fe7683-ps.csv</td>\n",
       "      <td>{'text': 'Working as Data Scientist, TCS Hyder...</td>\n",
       "      <td>{}</td>\n",
       "      <td>2022-04-01 08:06:57.929584+00:00</td>\n",
       "      <td>2022-04-01 10:51:44.918037+00:00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>171</td>\n",
       "      <td>[{'id': 61, 'completed_by': {'id': 1, 'email':...</td>\n",
       "      <td>[]</td>\n",
       "      <td>04fe7683-ps.csv</td>\n",
       "      <td>{'text': 'Working as an Applications Engineer ...</td>\n",
       "      <td>{}</td>\n",
       "      <td>2022-04-01 08:06:57.929584+00:00</td>\n",
       "      <td>2022-04-01 10:51:21.280451+00:00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>169</td>\n",
       "      <td>[{'id': 59, 'completed_by': {'id': 1, 'email':...</td>\n",
       "      <td>[]</td>\n",
       "      <td>04fe7683-ps.csv</td>\n",
       "      <td>{'text': 'Client: Hyundai,Hyderabad           ...</td>\n",
       "      <td>{}</td>\n",
       "      <td>2022-04-01 08:06:57.928587+00:00</td>\n",
       "      <td>2022-04-01 10:49:26.377254+00:00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>168</td>\n",
       "      <td>[{'id': 58, 'completed_by': {'id': 1, 'email':...</td>\n",
       "      <td>[]</td>\n",
       "      <td>04fe7683-ps.csv</td>\n",
       "      <td>{'text': 'COLLABERA TECHNOLOGIES PRIVATE LIMIT...</td>\n",
       "      <td>{}</td>\n",
       "      <td>2022-04-01 08:06:57.928587+00:00</td>\n",
       "      <td>2022-04-01 10:48:42.376802+00:00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>167</td>\n",
       "      <td>[{'id': 57, 'completed_by': {'id': 1, 'email':...</td>\n",
       "      <td>[]</td>\n",
       "      <td>04fe7683-ps.csv</td>\n",
       "      <td>{'text': 'Senior Process Executive\n",
       "Infosys\n",
       "07/...</td>\n",
       "      <td>{}</td>\n",
       "      <td>2022-04-01 08:06:57.928587+00:00</td>\n",
       "      <td>2022-04-01 10:48:13.177013+00:00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>166</td>\n",
       "      <td>[{'id': 56, 'completed_by': {'id': 1, 'email':...</td>\n",
       "      <td>[]</td>\n",
       "      <td>04fe7683-ps.csv</td>\n",
       "      <td>{'text': 'Organization – Synechron, Pune\n",
       "Desig...</td>\n",
       "      <td>{}</td>\n",
       "      <td>2022-04-01 08:06:57.928587+00:00</td>\n",
       "      <td>2022-04-01 10:47:37.127892+00:00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>165</td>\n",
       "      <td>[{'id': 55, 'completed_by': {'id': 1, 'email':...</td>\n",
       "      <td>[]</td>\n",
       "      <td>04fe7683-ps.csv</td>\n",
       "      <td>{'text': 'Decision minds\n",
       "Junior Data scientist...</td>\n",
       "      <td>{}</td>\n",
       "      <td>2022-04-01 08:06:57.928587+00:00</td>\n",
       "      <td>2022-04-01 10:47:15.428344+00:00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>164</td>\n",
       "      <td>[{'id': 54, 'completed_by': {'id': 1, 'email':...</td>\n",
       "      <td>[]</td>\n",
       "      <td>04fe7683-ps.csv</td>\n",
       "      <td>{'text': 'Commonwealth Bank of Australia\n",
       "Data ...</td>\n",
       "      <td>{}</td>\n",
       "      <td>2022-04-01 08:06:57.928587+00:00</td>\n",
       "      <td>2022-04-01 10:46:55.981565+00:00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>163</td>\n",
       "      <td>[{'id': 53, 'completed_by': {'id': 1, 'email':...</td>\n",
       "      <td>[]</td>\n",
       "      <td>04fe7683-ps.csv</td>\n",
       "      <td>{'text': 'NOV’16 – OCT’17:  Tech Mahindra as A...</td>\n",
       "      <td>{}</td>\n",
       "      <td>2022-04-01 08:06:57.928587+00:00</td>\n",
       "      <td>2022-04-01 10:41:23.526053+00:00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>162</td>\n",
       "      <td>[{'id': 52, 'completed_by': {'id': 1, 'email':...</td>\n",
       "      <td>[]</td>\n",
       "      <td>04fe7683-ps.csv</td>\n",
       "      <td>{'text': 'September 2020 – Current\n",
       "Python Deve...</td>\n",
       "      <td>{}</td>\n",
       "      <td>2022-04-01 08:06:57.928587+00:00</td>\n",
       "      <td>2022-04-01 10:40:40.055300+00:00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>161</td>\n",
       "      <td>[{'id': 51, 'completed_by': {'id': 1, 'email':...</td>\n",
       "      <td>[]</td>\n",
       "      <td>04fe7683-ps.csv</td>\n",
       "      <td>{'text': 'Working as python developer in Brio ...</td>\n",
       "      <td>{}</td>\n",
       "      <td>2022-04-01 08:06:57.928587+00:00</td>\n",
       "      <td>2022-04-01 10:36:22.307305+00:00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>160</td>\n",
       "      <td>[{'id': 50, 'completed_by': {'id': 1, 'email':...</td>\n",
       "      <td>[]</td>\n",
       "      <td>04fe7683-ps.csv</td>\n",
       "      <td>{'text': 'JAN 2020 – PRESENT\n",
       "DATA ANALYST, WEB...</td>\n",
       "      <td>{}</td>\n",
       "      <td>2022-04-01 08:06:57.928587+00:00</td>\n",
       "      <td>2022-04-01 10:35:12.218251+00:00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>173</td>\n",
       "      <td>[{'id': 63, 'completed_by': {'id': 1, 'email':...</td>\n",
       "      <td>[]</td>\n",
       "      <td>04fe7683-ps.csv</td>\n",
       "      <td>{'text': 'Data scientist – Intern\n",
       "Innodatatics...</td>\n",
       "      <td>{}</td>\n",
       "      <td>2022-04-01 08:06:57.929584+00:00</td>\n",
       "      <td>2022-04-01 08:06:57.929584+00:00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>174</td>\n",
       "      <td>[{'id': 64, 'completed_by': {'id': 1, 'email':...</td>\n",
       "      <td>[]</td>\n",
       "      <td>04fe7683-ps.csv</td>\n",
       "      <td>{'text': 'Senior Data Scientist\n",
       "Capgemini\n",
       " \n",
       "20...</td>\n",
       "      <td>{}</td>\n",
       "      <td>2022-04-01 08:06:57.929584+00:00</td>\n",
       "      <td>2022-04-01 08:06:57.929584+00:00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>175</td>\n",
       "      <td>[{'id': 65, 'completed_by': {'id': 1, 'email':...</td>\n",
       "      <td>[]</td>\n",
       "      <td>04fe7683-ps.csv</td>\n",
       "      <td>{'text': 'Working as Data Analyst at PROMAESTR...</td>\n",
       "      <td>{}</td>\n",
       "      <td>2022-04-01 08:06:57.929584+00:00</td>\n",
       "      <td>2022-04-01 08:06:57.929584+00:00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>176</td>\n",
       "      <td>[{'id': 66, 'completed_by': {'id': 1, 'email':...</td>\n",
       "      <td>[]</td>\n",
       "      <td>04fe7683-ps.csv</td>\n",
       "      <td>{'text': 'TECH MAHINDRA: HYDERABAD, TELANGANA ...</td>\n",
       "      <td>{}</td>\n",
       "      <td>2022-04-01 08:06:57.929584+00:00</td>\n",
       "      <td>2022-04-01 08:06:57.929584+00:00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>177</td>\n",
       "      <td>[{'id': 67, 'completed_by': {'id': 1, 'email':...</td>\n",
       "      <td>[]</td>\n",
       "      <td>04fe7683-ps.csv</td>\n",
       "      <td>{'text': 'TEKOPTIMIZE SOFTWARE INDIA Pvt. Ltd....</td>\n",
       "      <td>{}</td>\n",
       "      <td>2022-04-01 08:06:57.929584+00:00</td>\n",
       "      <td>2022-04-01 08:06:57.929584+00:00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>178</td>\n",
       "      <td>[{'id': 68, 'completed_by': {'id': 1, 'email':...</td>\n",
       "      <td>[]</td>\n",
       "      <td>04fe7683-ps.csv</td>\n",
       "      <td>{'text': 'Machine Learning Engineer\n",
       "PPC Minds ...</td>\n",
       "      <td>{}</td>\n",
       "      <td>2022-04-01 08:06:57.929584+00:00</td>\n",
       "      <td>2022-04-01 08:06:57.929584+00:00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>179</td>\n",
       "      <td>[{'id': 69, 'completed_by': {'id': 1, 'email':...</td>\n",
       "      <td>[]</td>\n",
       "      <td>04fe7683-ps.csv</td>\n",
       "      <td>{'text': 'Data Scientist Consultant\n",
       "Rubixe\n",
       "11/...</td>\n",
       "      <td>{}</td>\n",
       "      <td>2022-04-01 08:06:57.929584+00:00</td>\n",
       "      <td>2022-04-01 08:06:57.929584+00:00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>156</td>\n",
       "      <td>[{'id': 46, 'completed_by': {'id': 1, 'email':...</td>\n",
       "      <td>[]</td>\n",
       "      <td>04fe7683-ps.csv</td>\n",
       "      <td>{'text': 'Codesets IT Solutions (INDIA) Pvt Lt...</td>\n",
       "      <td>{}</td>\n",
       "      <td>2022-04-01 08:06:57.928587+00:00</td>\n",
       "      <td>2022-04-01 08:06:57.928587+00:00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>157</td>\n",
       "      <td>[{'id': 47, 'completed_by': {'id': 1, 'email':...</td>\n",
       "      <td>[]</td>\n",
       "      <td>04fe7683-ps.csv</td>\n",
       "      <td>{'text': 'Cyient: I had 2years of experience a...</td>\n",
       "      <td>{}</td>\n",
       "      <td>2022-04-01 08:06:57.928587+00:00</td>\n",
       "      <td>2022-04-01 08:06:57.928587+00:00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>158</td>\n",
       "      <td>[{'id': 48, 'completed_by': {'id': 1, 'email':...</td>\n",
       "      <td>[]</td>\n",
       "      <td>04fe7683-ps.csv</td>\n",
       "      <td>{'text': 'Worked as Senior Associate in Wipro ...</td>\n",
       "      <td>{}</td>\n",
       "      <td>2022-04-01 08:06:57.928587+00:00</td>\n",
       "      <td>2022-04-01 08:06:57.928587+00:00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>159</td>\n",
       "      <td>[{'id': 49, 'completed_by': {'id': 1, 'email':...</td>\n",
       "      <td>[]</td>\n",
       "      <td>04fe7683-ps.csv</td>\n",
       "      <td>{'text': 'JUNE 2019 - PRESENT\n",
       "Data Science Eng...</td>\n",
       "      <td>{}</td>\n",
       "      <td>2022-04-01 08:06:57.928587+00:00</td>\n",
       "      <td>2022-04-01 08:06:57.928587+00:00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>170</td>\n",
       "      <td>[{'id': 60, 'completed_by': {'id': 1, 'email':...</td>\n",
       "      <td>[]</td>\n",
       "      <td>04fe7683-ps.csv</td>\n",
       "      <td>{'text': 'TATA Consultancy Services\n",
       "Machine Le...</td>\n",
       "      <td>{}</td>\n",
       "      <td>2022-04-01 08:06:57.928587+00:00</td>\n",
       "      <td>2022-04-01 08:06:57.928587+00:00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>140</td>\n",
       "      <td>[{'id': 30, 'completed_by': {'id': 1, 'email':...</td>\n",
       "      <td>[]</td>\n",
       "      <td>04fe7683-ps.csv</td>\n",
       "      <td>{'text': 'Data Analyst with 2+ experience in p...</td>\n",
       "      <td>{}</td>\n",
       "      <td>2022-04-01 08:06:57.927573+00:00</td>\n",
       "      <td>2022-04-01 08:06:57.927573+00:00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>141</td>\n",
       "      <td>[{'id': 31, 'completed_by': {'id': 1, 'email':...</td>\n",
       "      <td>[]</td>\n",
       "      <td>04fe7683-ps.csv</td>\n",
       "      <td>{'text': '07/2018 – Present Data Scientist\n",
       "Wip...</td>\n",
       "      <td>{}</td>\n",
       "      <td>2022-04-01 08:06:57.927573+00:00</td>\n",
       "      <td>2022-04-01 08:06:57.927573+00:00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>142</td>\n",
       "      <td>[{'id': 32, 'completed_by': {'id': 1, 'email':...</td>\n",
       "      <td>[]</td>\n",
       "      <td>04fe7683-ps.csv</td>\n",
       "      <td>{'text': 'Data Scientist\n",
       "FIRST TECH Consulting...</td>\n",
       "      <td>{}</td>\n",
       "      <td>2022-04-01 08:06:57.927573+00:00</td>\n",
       "      <td>2022-04-01 08:06:57.927573+00:00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>143</td>\n",
       "      <td>[{'id': 33, 'completed_by': {'id': 1, 'email':...</td>\n",
       "      <td>[]</td>\n",
       "      <td>04fe7683-ps.csv</td>\n",
       "      <td>{'text': 'Present working as Data Scientist fo...</td>\n",
       "      <td>{}</td>\n",
       "      <td>2022-04-01 08:06:57.927573+00:00</td>\n",
       "      <td>2022-04-01 08:06:57.927573+00:00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>144</td>\n",
       "      <td>[{'id': 34, 'completed_by': {'id': 1, 'email':...</td>\n",
       "      <td>[]</td>\n",
       "      <td>04fe7683-ps.csv</td>\n",
       "      <td>{'text': 'Working as Data Scientist, TCS Hyder...</td>\n",
       "      <td>{}</td>\n",
       "      <td>2022-04-01 08:06:57.927573+00:00</td>\n",
       "      <td>2022-04-01 08:06:57.927573+00:00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>145</td>\n",
       "      <td>[{'id': 35, 'completed_by': {'id': 1, 'email':...</td>\n",
       "      <td>[]</td>\n",
       "      <td>04fe7683-ps.csv</td>\n",
       "      <td>{'text': 'Software Engineer | Sagarsoft (India...</td>\n",
       "      <td>{}</td>\n",
       "      <td>2022-04-01 08:06:57.927573+00:00</td>\n",
       "      <td>2022-04-01 08:06:57.927573+00:00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>146</td>\n",
       "      <td>[{'id': 36, 'completed_by': {'id': 1, 'email':...</td>\n",
       "      <td>[]</td>\n",
       "      <td>04fe7683-ps.csv</td>\n",
       "      <td>{'text': 'Senior Software Engineer\n",
       "Altran\n",
       "Feb ...</td>\n",
       "      <td>{}</td>\n",
       "      <td>2022-04-01 08:06:57.927573+00:00</td>\n",
       "      <td>2022-04-01 08:06:57.927573+00:00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>147</td>\n",
       "      <td>[{'id': 37, 'completed_by': {'id': 1, 'email':...</td>\n",
       "      <td>[]</td>\n",
       "      <td>04fe7683-ps.csv</td>\n",
       "      <td>{'text': 'Software Engineer\n",
       "Reliance Jio\n",
       "Aug 2...</td>\n",
       "      <td>{}</td>\n",
       "      <td>2022-04-01 08:06:57.927573+00:00</td>\n",
       "      <td>2022-04-01 08:06:57.927573+00:00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>148</td>\n",
       "      <td>[{'id': 38, 'completed_by': {'id': 1, 'email':...</td>\n",
       "      <td>[]</td>\n",
       "      <td>04fe7683-ps.csv</td>\n",
       "      <td>{'text': 'Worked as Python Developer at Optum ...</td>\n",
       "      <td>{}</td>\n",
       "      <td>2022-04-01 08:06:57.927573+00:00</td>\n",
       "      <td>2022-04-01 08:06:57.927573+00:00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>149</td>\n",
       "      <td>[{'id': 39, 'completed_by': {'id': 1, 'email':...</td>\n",
       "      <td>[]</td>\n",
       "      <td>04fe7683-ps.csv</td>\n",
       "      <td>{'text': 'Software Engineer\n",
       "Pega Systems\n",
       "07/20...</td>\n",
       "      <td>{}</td>\n",
       "      <td>2022-04-01 08:06:57.927573+00:00</td>\n",
       "      <td>2022-04-01 08:06:57.927573+00:00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>150</td>\n",
       "      <td>[{'id': 40, 'completed_by': {'id': 1, 'email':...</td>\n",
       "      <td>[]</td>\n",
       "      <td>04fe7683-ps.csv</td>\n",
       "      <td>{'text': 'Data analytics professional with 3.6...</td>\n",
       "      <td>{}</td>\n",
       "      <td>2022-04-01 08:06:57.927573+00:00</td>\n",
       "      <td>2022-04-01 08:06:57.927573+00:00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>151</td>\n",
       "      <td>[{'id': 41, 'completed_by': {'id': 1, 'email':...</td>\n",
       "      <td>[]</td>\n",
       "      <td>04fe7683-ps.csv</td>\n",
       "      <td>{'text': 'Working as Software Engineer PERITO ...</td>\n",
       "      <td>{}</td>\n",
       "      <td>2022-04-01 08:06:57.927573+00:00</td>\n",
       "      <td>2022-04-01 08:06:57.927573+00:00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>152</td>\n",
       "      <td>[{'id': 42, 'completed_by': {'id': 1, 'email':...</td>\n",
       "      <td>[]</td>\n",
       "      <td>04fe7683-ps.csv</td>\n",
       "      <td>{'text': 'Working as Software Developer in And...</td>\n",
       "      <td>{}</td>\n",
       "      <td>2022-04-01 08:06:57.927573+00:00</td>\n",
       "      <td>2022-04-01 08:06:57.927573+00:00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>153</td>\n",
       "      <td>[{'id': 43, 'completed_by': {'id': 1, 'email':...</td>\n",
       "      <td>[]</td>\n",
       "      <td>04fe7683-ps.csv</td>\n",
       "      <td>{'text': 'Data Scientist | Senior Software Eng...</td>\n",
       "      <td>{}</td>\n",
       "      <td>2022-04-01 08:06:57.927573+00:00</td>\n",
       "      <td>2022-04-01 08:06:57.927573+00:00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>154</td>\n",
       "      <td>[{'id': 44, 'completed_by': {'id': 1, 'email':...</td>\n",
       "      <td>[]</td>\n",
       "      <td>04fe7683-ps.csv</td>\n",
       "      <td>{'text': 'Accenture Services Pvt. Ltd.\n",
       "Associa...</td>\n",
       "      <td>{}</td>\n",
       "      <td>2022-04-01 08:06:57.927573+00:00</td>\n",
       "      <td>2022-04-01 08:06:57.927573+00:00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>155</td>\n",
       "      <td>[{'id': 45, 'completed_by': {'id': 1, 'email':...</td>\n",
       "      <td>[]</td>\n",
       "      <td>04fe7683-ps.csv</td>\n",
       "      <td>{'text': 'Norm Software, Hyderabad (Feb 2020 t...</td>\n",
       "      <td>{}</td>\n",
       "      <td>2022-04-01 08:06:57.927573+00:00</td>\n",
       "      <td>2022-04-01 08:06:57.927573+00:00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>130</td>\n",
       "      <td>[{'id': 20, 'completed_by': {'id': 1, 'email':...</td>\n",
       "      <td>[]</td>\n",
       "      <td>04fe7683-ps.csv</td>\n",
       "      <td>{'text': '3+ years of Experience in Sysark Dat...</td>\n",
       "      <td>{}</td>\n",
       "      <td>2022-04-01 08:06:57.926574+00:00</td>\n",
       "      <td>2022-04-01 08:06:57.926574+00:00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>131</td>\n",
       "      <td>[{'id': 21, 'completed_by': {'id': 1, 'email':...</td>\n",
       "      <td>[]</td>\n",
       "      <td>04fe7683-ps.csv</td>\n",
       "      <td>{'text': 'PROJECT 1: Customer Feedback Analysi...</td>\n",
       "      <td>{}</td>\n",
       "      <td>2022-04-01 08:06:57.926574+00:00</td>\n",
       "      <td>2022-04-01 08:06:57.926574+00:00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>132</td>\n",
       "      <td>[{'id': 22, 'completed_by': {'id': 1, 'email':...</td>\n",
       "      <td>[]</td>\n",
       "      <td>04fe7683-ps.csv</td>\n",
       "      <td>{'text': 'PROJECT I\n",
       "Company: IFS India Marcant...</td>\n",
       "      <td>{}</td>\n",
       "      <td>2022-04-01 08:06:57.926574+00:00</td>\n",
       "      <td>2022-04-01 08:06:57.926574+00:00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>133</td>\n",
       "      <td>[{'id': 23, 'completed_by': {'id': 1, 'email':...</td>\n",
       "      <td>[]</td>\n",
       "      <td>04fe7683-ps.csv</td>\n",
       "      <td>{'text': 'Khushi Software Services Pvt Ltd.\n",
       "De...</td>\n",
       "      <td>{}</td>\n",
       "      <td>2022-04-01 08:06:57.926574+00:00</td>\n",
       "      <td>2022-04-01 08:06:57.926574+00:00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>134</td>\n",
       "      <td>[{'id': 24, 'completed_by': {'id': 1, 'email':...</td>\n",
       "      <td>[]</td>\n",
       "      <td>04fe7683-ps.csv</td>\n",
       "      <td>{'text': 'Working as Data Analyst at ESMOB TEC...</td>\n",
       "      <td>{}</td>\n",
       "      <td>2022-04-01 08:06:57.926574+00:00</td>\n",
       "      <td>2022-04-01 08:06:57.926574+00:00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>135</td>\n",
       "      <td>[{'id': 25, 'completed_by': {'id': 1, 'email':...</td>\n",
       "      <td>[]</td>\n",
       "      <td>04fe7683-ps.csv</td>\n",
       "      <td>{'text': 'Company Name : TechMahindra ltd Hyde...</td>\n",
       "      <td>{}</td>\n",
       "      <td>2022-04-01 08:06:57.926574+00:00</td>\n",
       "      <td>2022-04-01 08:06:57.926574+00:00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>136</td>\n",
       "      <td>[{'id': 26, 'completed_by': {'id': 1, 'email':...</td>\n",
       "      <td>[]</td>\n",
       "      <td>04fe7683-ps.csv</td>\n",
       "      <td>{'text': '1.TCS (Tata Consultancy Services), H...</td>\n",
       "      <td>{}</td>\n",
       "      <td>2022-04-01 08:06:57.926574+00:00</td>\n",
       "      <td>2022-04-01 08:06:57.926574+00:00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>137</td>\n",
       "      <td>[{'id': 27, 'completed_by': {'id': 1, 'email':...</td>\n",
       "      <td>[]</td>\n",
       "      <td>04fe7683-ps.csv</td>\n",
       "      <td>{'text': 'IVEOND Consulting Pvt Ltd – Hyderaba...</td>\n",
       "      <td>{}</td>\n",
       "      <td>2022-04-01 08:06:57.926574+00:00</td>\n",
       "      <td>2022-04-01 08:06:57.926574+00:00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>138</td>\n",
       "      <td>[{'id': 28, 'completed_by': {'id': 1, 'email':...</td>\n",
       "      <td>[]</td>\n",
       "      <td>04fe7683-ps.csv</td>\n",
       "      <td>{'text': 'Working as a Data Scientist in Tech ...</td>\n",
       "      <td>{}</td>\n",
       "      <td>2022-04-01 08:06:57.926574+00:00</td>\n",
       "      <td>2022-04-01 08:06:57.926574+00:00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>139</td>\n",
       "      <td>[{'id': 29, 'completed_by': {'id': 1, 'email':...</td>\n",
       "      <td>[]</td>\n",
       "      <td>04fe7683-ps.csv</td>\n",
       "      <td>{'text': 'Working as Data Scientist in Tech Ma...</td>\n",
       "      <td>{}</td>\n",
       "      <td>2022-04-01 08:06:57.926574+00:00</td>\n",
       "      <td>2022-04-01 08:06:57.926574+00:00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                        annotations predictions  \\\n",
       "0   172  [{'id': 62, 'completed_by': {'id': 1, 'email':...          []   \n",
       "1   171  [{'id': 61, 'completed_by': {'id': 1, 'email':...          []   \n",
       "2   169  [{'id': 59, 'completed_by': {'id': 1, 'email':...          []   \n",
       "3   168  [{'id': 58, 'completed_by': {'id': 1, 'email':...          []   \n",
       "4   167  [{'id': 57, 'completed_by': {'id': 1, 'email':...          []   \n",
       "5   166  [{'id': 56, 'completed_by': {'id': 1, 'email':...          []   \n",
       "6   165  [{'id': 55, 'completed_by': {'id': 1, 'email':...          []   \n",
       "7   164  [{'id': 54, 'completed_by': {'id': 1, 'email':...          []   \n",
       "8   163  [{'id': 53, 'completed_by': {'id': 1, 'email':...          []   \n",
       "9   162  [{'id': 52, 'completed_by': {'id': 1, 'email':...          []   \n",
       "10  161  [{'id': 51, 'completed_by': {'id': 1, 'email':...          []   \n",
       "11  160  [{'id': 50, 'completed_by': {'id': 1, 'email':...          []   \n",
       "12  173  [{'id': 63, 'completed_by': {'id': 1, 'email':...          []   \n",
       "13  174  [{'id': 64, 'completed_by': {'id': 1, 'email':...          []   \n",
       "14  175  [{'id': 65, 'completed_by': {'id': 1, 'email':...          []   \n",
       "15  176  [{'id': 66, 'completed_by': {'id': 1, 'email':...          []   \n",
       "16  177  [{'id': 67, 'completed_by': {'id': 1, 'email':...          []   \n",
       "17  178  [{'id': 68, 'completed_by': {'id': 1, 'email':...          []   \n",
       "18  179  [{'id': 69, 'completed_by': {'id': 1, 'email':...          []   \n",
       "19  156  [{'id': 46, 'completed_by': {'id': 1, 'email':...          []   \n",
       "20  157  [{'id': 47, 'completed_by': {'id': 1, 'email':...          []   \n",
       "21  158  [{'id': 48, 'completed_by': {'id': 1, 'email':...          []   \n",
       "22  159  [{'id': 49, 'completed_by': {'id': 1, 'email':...          []   \n",
       "23  170  [{'id': 60, 'completed_by': {'id': 1, 'email':...          []   \n",
       "24  140  [{'id': 30, 'completed_by': {'id': 1, 'email':...          []   \n",
       "25  141  [{'id': 31, 'completed_by': {'id': 1, 'email':...          []   \n",
       "26  142  [{'id': 32, 'completed_by': {'id': 1, 'email':...          []   \n",
       "27  143  [{'id': 33, 'completed_by': {'id': 1, 'email':...          []   \n",
       "28  144  [{'id': 34, 'completed_by': {'id': 1, 'email':...          []   \n",
       "29  145  [{'id': 35, 'completed_by': {'id': 1, 'email':...          []   \n",
       "30  146  [{'id': 36, 'completed_by': {'id': 1, 'email':...          []   \n",
       "31  147  [{'id': 37, 'completed_by': {'id': 1, 'email':...          []   \n",
       "32  148  [{'id': 38, 'completed_by': {'id': 1, 'email':...          []   \n",
       "33  149  [{'id': 39, 'completed_by': {'id': 1, 'email':...          []   \n",
       "34  150  [{'id': 40, 'completed_by': {'id': 1, 'email':...          []   \n",
       "35  151  [{'id': 41, 'completed_by': {'id': 1, 'email':...          []   \n",
       "36  152  [{'id': 42, 'completed_by': {'id': 1, 'email':...          []   \n",
       "37  153  [{'id': 43, 'completed_by': {'id': 1, 'email':...          []   \n",
       "38  154  [{'id': 44, 'completed_by': {'id': 1, 'email':...          []   \n",
       "39  155  [{'id': 45, 'completed_by': {'id': 1, 'email':...          []   \n",
       "40  130  [{'id': 20, 'completed_by': {'id': 1, 'email':...          []   \n",
       "41  131  [{'id': 21, 'completed_by': {'id': 1, 'email':...          []   \n",
       "42  132  [{'id': 22, 'completed_by': {'id': 1, 'email':...          []   \n",
       "43  133  [{'id': 23, 'completed_by': {'id': 1, 'email':...          []   \n",
       "44  134  [{'id': 24, 'completed_by': {'id': 1, 'email':...          []   \n",
       "45  135  [{'id': 25, 'completed_by': {'id': 1, 'email':...          []   \n",
       "46  136  [{'id': 26, 'completed_by': {'id': 1, 'email':...          []   \n",
       "47  137  [{'id': 27, 'completed_by': {'id': 1, 'email':...          []   \n",
       "48  138  [{'id': 28, 'completed_by': {'id': 1, 'email':...          []   \n",
       "49  139  [{'id': 29, 'completed_by': {'id': 1, 'email':...          []   \n",
       "\n",
       "        file_upload                                               data meta  \\\n",
       "0   04fe7683-ps.csv  {'text': 'Working as Data Scientist, TCS Hyder...   {}   \n",
       "1   04fe7683-ps.csv  {'text': 'Working as an Applications Engineer ...   {}   \n",
       "2   04fe7683-ps.csv  {'text': 'Client: Hyundai,Hyderabad           ...   {}   \n",
       "3   04fe7683-ps.csv  {'text': 'COLLABERA TECHNOLOGIES PRIVATE LIMIT...   {}   \n",
       "4   04fe7683-ps.csv  {'text': 'Senior Process Executive\n",
       "Infosys\n",
       "07/...   {}   \n",
       "5   04fe7683-ps.csv  {'text': 'Organization – Synechron, Pune\n",
       "Desig...   {}   \n",
       "6   04fe7683-ps.csv  {'text': 'Decision minds\n",
       "Junior Data scientist...   {}   \n",
       "7   04fe7683-ps.csv  {'text': 'Commonwealth Bank of Australia\n",
       "Data ...   {}   \n",
       "8   04fe7683-ps.csv  {'text': 'NOV’16 – OCT’17:  Tech Mahindra as A...   {}   \n",
       "9   04fe7683-ps.csv  {'text': 'September 2020 – Current\n",
       "Python Deve...   {}   \n",
       "10  04fe7683-ps.csv  {'text': 'Working as python developer in Brio ...   {}   \n",
       "11  04fe7683-ps.csv  {'text': 'JAN 2020 – PRESENT\n",
       "DATA ANALYST, WEB...   {}   \n",
       "12  04fe7683-ps.csv  {'text': 'Data scientist – Intern\n",
       "Innodatatics...   {}   \n",
       "13  04fe7683-ps.csv  {'text': 'Senior Data Scientist\n",
       "Capgemini\n",
       " \n",
       "20...   {}   \n",
       "14  04fe7683-ps.csv  {'text': 'Working as Data Analyst at PROMAESTR...   {}   \n",
       "15  04fe7683-ps.csv  {'text': 'TECH MAHINDRA: HYDERABAD, TELANGANA ...   {}   \n",
       "16  04fe7683-ps.csv  {'text': 'TEKOPTIMIZE SOFTWARE INDIA Pvt. Ltd....   {}   \n",
       "17  04fe7683-ps.csv  {'text': 'Machine Learning Engineer\n",
       "PPC Minds ...   {}   \n",
       "18  04fe7683-ps.csv  {'text': 'Data Scientist Consultant\n",
       "Rubixe\n",
       "11/...   {}   \n",
       "19  04fe7683-ps.csv  {'text': 'Codesets IT Solutions (INDIA) Pvt Lt...   {}   \n",
       "20  04fe7683-ps.csv  {'text': 'Cyient: I had 2years of experience a...   {}   \n",
       "21  04fe7683-ps.csv  {'text': 'Worked as Senior Associate in Wipro ...   {}   \n",
       "22  04fe7683-ps.csv  {'text': 'JUNE 2019 - PRESENT\n",
       "Data Science Eng...   {}   \n",
       "23  04fe7683-ps.csv  {'text': 'TATA Consultancy Services\n",
       "Machine Le...   {}   \n",
       "24  04fe7683-ps.csv  {'text': 'Data Analyst with 2+ experience in p...   {}   \n",
       "25  04fe7683-ps.csv  {'text': '07/2018 – Present Data Scientist\n",
       "Wip...   {}   \n",
       "26  04fe7683-ps.csv  {'text': 'Data Scientist\n",
       "FIRST TECH Consulting...   {}   \n",
       "27  04fe7683-ps.csv  {'text': 'Present working as Data Scientist fo...   {}   \n",
       "28  04fe7683-ps.csv  {'text': 'Working as Data Scientist, TCS Hyder...   {}   \n",
       "29  04fe7683-ps.csv  {'text': 'Software Engineer | Sagarsoft (India...   {}   \n",
       "30  04fe7683-ps.csv  {'text': 'Senior Software Engineer\n",
       "Altran\n",
       "Feb ...   {}   \n",
       "31  04fe7683-ps.csv  {'text': 'Software Engineer\n",
       "Reliance Jio\n",
       "Aug 2...   {}   \n",
       "32  04fe7683-ps.csv  {'text': 'Worked as Python Developer at Optum ...   {}   \n",
       "33  04fe7683-ps.csv  {'text': 'Software Engineer\n",
       "Pega Systems\n",
       "07/20...   {}   \n",
       "34  04fe7683-ps.csv  {'text': 'Data analytics professional with 3.6...   {}   \n",
       "35  04fe7683-ps.csv  {'text': 'Working as Software Engineer PERITO ...   {}   \n",
       "36  04fe7683-ps.csv  {'text': 'Working as Software Developer in And...   {}   \n",
       "37  04fe7683-ps.csv  {'text': 'Data Scientist | Senior Software Eng...   {}   \n",
       "38  04fe7683-ps.csv  {'text': 'Accenture Services Pvt. Ltd.\n",
       "Associa...   {}   \n",
       "39  04fe7683-ps.csv  {'text': 'Norm Software, Hyderabad (Feb 2020 t...   {}   \n",
       "40  04fe7683-ps.csv  {'text': '3+ years of Experience in Sysark Dat...   {}   \n",
       "41  04fe7683-ps.csv  {'text': 'PROJECT 1: Customer Feedback Analysi...   {}   \n",
       "42  04fe7683-ps.csv  {'text': 'PROJECT I\n",
       "Company: IFS India Marcant...   {}   \n",
       "43  04fe7683-ps.csv  {'text': 'Khushi Software Services Pvt Ltd.\n",
       "De...   {}   \n",
       "44  04fe7683-ps.csv  {'text': 'Working as Data Analyst at ESMOB TEC...   {}   \n",
       "45  04fe7683-ps.csv  {'text': 'Company Name : TechMahindra ltd Hyde...   {}   \n",
       "46  04fe7683-ps.csv  {'text': '1.TCS (Tata Consultancy Services), H...   {}   \n",
       "47  04fe7683-ps.csv  {'text': 'IVEOND Consulting Pvt Ltd – Hyderaba...   {}   \n",
       "48  04fe7683-ps.csv  {'text': 'Working as a Data Scientist in Tech ...   {}   \n",
       "49  04fe7683-ps.csv  {'text': 'Working as Data Scientist in Tech Ma...   {}   \n",
       "\n",
       "                         created_at                       updated_at  project  \n",
       "0  2022-04-01 08:06:57.929584+00:00 2022-04-01 10:51:44.918037+00:00        7  \n",
       "1  2022-04-01 08:06:57.929584+00:00 2022-04-01 10:51:21.280451+00:00        7  \n",
       "2  2022-04-01 08:06:57.928587+00:00 2022-04-01 10:49:26.377254+00:00        7  \n",
       "3  2022-04-01 08:06:57.928587+00:00 2022-04-01 10:48:42.376802+00:00        7  \n",
       "4  2022-04-01 08:06:57.928587+00:00 2022-04-01 10:48:13.177013+00:00        7  \n",
       "5  2022-04-01 08:06:57.928587+00:00 2022-04-01 10:47:37.127892+00:00        7  \n",
       "6  2022-04-01 08:06:57.928587+00:00 2022-04-01 10:47:15.428344+00:00        7  \n",
       "7  2022-04-01 08:06:57.928587+00:00 2022-04-01 10:46:55.981565+00:00        7  \n",
       "8  2022-04-01 08:06:57.928587+00:00 2022-04-01 10:41:23.526053+00:00        7  \n",
       "9  2022-04-01 08:06:57.928587+00:00 2022-04-01 10:40:40.055300+00:00        7  \n",
       "10 2022-04-01 08:06:57.928587+00:00 2022-04-01 10:36:22.307305+00:00        7  \n",
       "11 2022-04-01 08:06:57.928587+00:00 2022-04-01 10:35:12.218251+00:00        7  \n",
       "12 2022-04-01 08:06:57.929584+00:00 2022-04-01 08:06:57.929584+00:00        7  \n",
       "13 2022-04-01 08:06:57.929584+00:00 2022-04-01 08:06:57.929584+00:00        7  \n",
       "14 2022-04-01 08:06:57.929584+00:00 2022-04-01 08:06:57.929584+00:00        7  \n",
       "15 2022-04-01 08:06:57.929584+00:00 2022-04-01 08:06:57.929584+00:00        7  \n",
       "16 2022-04-01 08:06:57.929584+00:00 2022-04-01 08:06:57.929584+00:00        7  \n",
       "17 2022-04-01 08:06:57.929584+00:00 2022-04-01 08:06:57.929584+00:00        7  \n",
       "18 2022-04-01 08:06:57.929584+00:00 2022-04-01 08:06:57.929584+00:00        7  \n",
       "19 2022-04-01 08:06:57.928587+00:00 2022-04-01 08:06:57.928587+00:00        7  \n",
       "20 2022-04-01 08:06:57.928587+00:00 2022-04-01 08:06:57.928587+00:00        7  \n",
       "21 2022-04-01 08:06:57.928587+00:00 2022-04-01 08:06:57.928587+00:00        7  \n",
       "22 2022-04-01 08:06:57.928587+00:00 2022-04-01 08:06:57.928587+00:00        7  \n",
       "23 2022-04-01 08:06:57.928587+00:00 2022-04-01 08:06:57.928587+00:00        7  \n",
       "24 2022-04-01 08:06:57.927573+00:00 2022-04-01 08:06:57.927573+00:00        7  \n",
       "25 2022-04-01 08:06:57.927573+00:00 2022-04-01 08:06:57.927573+00:00        7  \n",
       "26 2022-04-01 08:06:57.927573+00:00 2022-04-01 08:06:57.927573+00:00        7  \n",
       "27 2022-04-01 08:06:57.927573+00:00 2022-04-01 08:06:57.927573+00:00        7  \n",
       "28 2022-04-01 08:06:57.927573+00:00 2022-04-01 08:06:57.927573+00:00        7  \n",
       "29 2022-04-01 08:06:57.927573+00:00 2022-04-01 08:06:57.927573+00:00        7  \n",
       "30 2022-04-01 08:06:57.927573+00:00 2022-04-01 08:06:57.927573+00:00        7  \n",
       "31 2022-04-01 08:06:57.927573+00:00 2022-04-01 08:06:57.927573+00:00        7  \n",
       "32 2022-04-01 08:06:57.927573+00:00 2022-04-01 08:06:57.927573+00:00        7  \n",
       "33 2022-04-01 08:06:57.927573+00:00 2022-04-01 08:06:57.927573+00:00        7  \n",
       "34 2022-04-01 08:06:57.927573+00:00 2022-04-01 08:06:57.927573+00:00        7  \n",
       "35 2022-04-01 08:06:57.927573+00:00 2022-04-01 08:06:57.927573+00:00        7  \n",
       "36 2022-04-01 08:06:57.927573+00:00 2022-04-01 08:06:57.927573+00:00        7  \n",
       "37 2022-04-01 08:06:57.927573+00:00 2022-04-01 08:06:57.927573+00:00        7  \n",
       "38 2022-04-01 08:06:57.927573+00:00 2022-04-01 08:06:57.927573+00:00        7  \n",
       "39 2022-04-01 08:06:57.927573+00:00 2022-04-01 08:06:57.927573+00:00        7  \n",
       "40 2022-04-01 08:06:57.926574+00:00 2022-04-01 08:06:57.926574+00:00        7  \n",
       "41 2022-04-01 08:06:57.926574+00:00 2022-04-01 08:06:57.926574+00:00        7  \n",
       "42 2022-04-01 08:06:57.926574+00:00 2022-04-01 08:06:57.926574+00:00        7  \n",
       "43 2022-04-01 08:06:57.926574+00:00 2022-04-01 08:06:57.926574+00:00        7  \n",
       "44 2022-04-01 08:06:57.926574+00:00 2022-04-01 08:06:57.926574+00:00        7  \n",
       "45 2022-04-01 08:06:57.926574+00:00 2022-04-01 08:06:57.926574+00:00        7  \n",
       "46 2022-04-01 08:06:57.926574+00:00 2022-04-01 08:06:57.926574+00:00        7  \n",
       "47 2022-04-01 08:06:57.926574+00:00 2022-04-01 08:06:57.926574+00:00        7  \n",
       "48 2022-04-01 08:06:57.926574+00:00 2022-04-01 08:06:57.926574+00:00        7  \n",
       "49 2022-04-01 08:06:57.926574+00:00 2022-04-01 08:06:57.926574+00:00        7  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TECH MAHINDRA: HYDERABAD, TELANGANA (DEC 2016 – PRESENT)'"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_data.data[15]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA = []\n",
    "for i in range(0,len(json_data)):\n",
    "    starts = [json_data.annotations[i][0]['result'][k]['value']['start'] for k in range(0,len(json_data.annotations[i][0]['result']))]\n",
    "    ends = [json_data.annotations[i][0]['result'][k]['value']['end'] for k in range(0,len(json_data.annotations[i][0]['result']))]\n",
    "    labels = [json_data.annotations[i][0]['result'][k]['value']['labels'][0] for k in range(0,len(json_data.annotations[i][0]['result']))]\n",
    "\n",
    "    entities = []\n",
    "    for j in range(0,len(starts)):\n",
    "        entities.append((starts[j],ends[j],labels[j]))\n",
    "    TRAIN_DATA.append((json_data.data[i]['text'],{'entities': entities}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Working as Data Scientist, TCS Hyderabad (1st July 2019to till date).',\n",
       "  {'entities': [(11, 25, 'designation'),\n",
       "    (27, 30, 'organization'),\n",
       "    (42, 67, 'date')]}),\n",
       " ('Working as an Applications Engineer in Oracle India Pvt ltd, Hyderabad from April 2018 to present.                                                                                                                                                                                        \\nWorked as an Associate Projects in Cognizant Technology Solutions, Hyderabad from August 2014 to April 2018.\\nWorked as a Software Engineer in Tech Mahindra ltd, Hyderabad from August 2013 to May 2014.\\n',\n",
       "  {'entities': [(14, 35, 'designation'),\n",
       "    (296, 314, 'designation'),\n",
       "    (404, 421, 'designation'),\n",
       "    (425, 442, 'organization'),\n",
       "    (39, 59, 'organization'),\n",
       "    (318, 348, 'organization'),\n",
       "    (76, 97, 'date'),\n",
       "    (365, 390, 'date'),\n",
       "    (459, 483, 'date')]})]"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_DATA[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created blank 'english language' model\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "{'ner': 100476.52390140161}\n",
      "Saved model to models\n",
      "Loading from models\n"
     ]
    }
   ],
   "source": [
    "# training data\n",
    "# TRAIN_DATA = dataset_to_train_data(\"text_final_train_annot\")\n",
    "\n",
    "\n",
    "def main(model=None, output_dir='./models', n_iter=10):\n",
    "    \"\"\"Load the model, set up the pipeline and train the entity recognizer.\"\"\"\n",
    "    if model is not None:\n",
    "        nlp = spacy.load(model)  # load existing spaCy model\n",
    "        print(\"Loaded model '%s'\" % model)\n",
    "    else:\n",
    "#         nlp = spacy.load('xx_ent_wiki_sm')  \n",
    "        nlp=spacy.load('en_core_web_sm')\n",
    "        print(\"Created blank 'english language' model\")\n",
    "\n",
    "    # create the built-in pipeline components and add them to the pipeline\n",
    "    # nlp.create_pipe works for built-ins that are registered with spaCy\n",
    "    if 'ner' not in nlp.pipe_names:\n",
    "        ner = nlp.create_pipe('ner')\n",
    "        nlp.add_pipe(ner, last=True)\n",
    "    # otherwise, get it so we can add labels\n",
    "    else:\n",
    "        ner = nlp.get_pipe('ner')\n",
    "\n",
    "    # add labels\n",
    "    for _, annotations in TRAIN_DATA:\n",
    "        for ent in annotations.get('entities'):\n",
    "            ner.add_label(ent[2])\n",
    "\n",
    "    # get names of other pipes to disable them during training\n",
    "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
    "    with nlp.disable_pipes(*other_pipes):  # only train NER\n",
    "        optimizer = nlp.begin_training()\n",
    "        examples = []\n",
    "        losses = {}\n",
    "        for text, annots in TRAIN_DATA:\n",
    "            examples.append(Example.from_dict(nlp.make_doc(text), annots))\n",
    "        nlp.initialize(lambda: examples)\n",
    "        for i in range(40):\n",
    "            print(i)\n",
    "            random.shuffle(examples)\n",
    "            for batch in minibatch(examples, size=32):\n",
    "                nlp.update(batch,losses=losses)\n",
    "        print(losses)\n",
    "\n",
    "    # test the trained model\n",
    "    for text, _ in TRAIN_DATA:\n",
    "        doc = nlp(text)\n",
    "#         print('Entities', [(ent.text, ent.label_) for ent in doc.ents])\n",
    "#         print('Tokens', [(t.text, t.ent_type_, t.ent_iob) for t in doc])\n",
    "\n",
    "    # save model to output directory\n",
    "    if output_dir is not None:\n",
    "        output_dir = Path(output_dir)\n",
    "        if not output_dir.exists():\n",
    "            output_dir.mkdir()\n",
    "        nlp.to_disk(output_dir)\n",
    "        print(\"Saved model to\", output_dir)\n",
    "\n",
    "        # test the saved model\n",
    "        print(\"Loading from\", output_dir)\n",
    "        nlp2 = spacy.load(output_dir)\n",
    "        for text, _ in TRAIN_DATA:\n",
    "            doc = nlp2(text)\n",
    "#             print('Entities', [(ent.text, ent.label_) for ent in doc.ents])\n",
    "#             print('Tokens', [(t.text, t.ent_type_, t.ent_iob) for t in doc])\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### checking the model on a sample text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      " ENTITIES : \n",
      "\n",
      "Data Scientist , designation\n",
      "TCS , organization\n",
      "1st July 2019to till date , date\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      " ENTITIES : \n",
      "\n",
      "Applications Engineer , designation\n",
      "Oracle India Pvt ltd , organization\n",
      "April 2018 to present , date\n",
      "Associate Projects , designation\n",
      "Cognizant Technology Solutions , organization\n",
      "August 2014 to April 2018 , date\n",
      "Software Engineer , designation\n",
      "Tech Mahindra ltd , organization\n",
      "August 2013 to May 2014. , date\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      " ENTITIES : \n",
      "\n",
      "Hyundai,Hyderabad , organization\n",
      "Sep 2020 – , date\n",
      "Data Analyst/Data Scientist , designation\n",
      "CMS Energy, Hyderabad , organization\n",
      "Apr 2018 – Aug 2020 , date\n",
      "Data Analyst/Data Scientist , organization\n",
      "Bank of the West, Hyderabad , organization\n",
      "Aug 2016 – Mar 2018 , date\n",
      "Data Analyst / Data Scientist , designation\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      " ENTITIES : \n",
      "\n",
      "COLLABERA TECHNOLOGIES PRIVATE LIMITED , organization\n",
      "Data Scientist , designation\n",
      "May 2021 to present , date\n",
      "SOFT CONNEX TECHNOLOGIES PRIVATE LIMITED , organization\n",
      "Data Analyst , designation\n",
      "December 2017 to April 2021 , date\n",
      "Software Engineer , designation\n",
      "October 2017 to November 2017 , date\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      " ENTITIES : \n",
      "\n",
      "Senior Process Executive , designation\n",
      "Infosys , organization\n",
      "07/2017 - Present , date\n",
      "Data Analyst - Internship , designation\n",
      "06/2021 - 08/2021 , date\n",
      "Data Analyst , designation\n",
      "Global Logic , organization\n",
      "Intern , designation\n",
      "Clossus360 , organization\n",
      "09/2014 - 05/2015 , date\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      " ENTITIES : \n",
      "\n",
      "Synechron , organization\n",
      "Data Scientist , designation\n",
      "February 2020 to till Date , date\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      " ENTITIES : \n",
      "\n",
      "Decision minds , organization\n",
      "Junior Data scientist , designation\n",
      "March 2020 – Present , date\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      " ENTITIES : \n",
      "\n",
      "Commonwealth Bank of Australia , organization\n",
      "Data Scientist , designation\n",
      "Jan 2021-Present , date\n",
      "Velankani Communications , organization\n",
      "Data Scientist , designation\n",
      "July 2020-Dec-2020 , date\n",
      "Tata Consultancy Services , organization\n",
      "Data Scientist , designation\n",
      "July 2016-June 2020 , date\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      " ENTITIES : \n",
      "\n",
      "NOV’16 – OCT’17 , date\n",
      "Tech Mahindra , organization\n",
      "Associate Software Engineer. , designation\n",
      "AUG’18 – OCT’20 , date\n",
      "Vitech Systems Asia Pvt. Ltd , organization\n",
      "Associate Developer , designation\n",
      "NOV’20 – Present , date\n",
      "KPMG , organization\n",
      "Data Scientist. , designation\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      " ENTITIES : \n",
      "\n",
      "September 2020 – , date\n",
      "Python Developer , designation\n",
      "June 2018 – August 2020 , date\n",
      "Python Developer , designation\n",
      "IEM (Development Section) , organization\n",
      "Jan 2014 – May 2018 , date\n",
      "Assistant Professor , designation\n",
      "IEM (Academic Section) , organization\n",
      "Jun 2012 – Dec 2013 , date\n",
      "System Administrator and Lecturer , designation\n",
      "May 2011 – Mar 2012 , date\n",
      "IT Executive , designation\n",
      "HIND-FAME Limited , organization\n",
      "Nov 2008 – Oct 2009 , date\n",
      "Technical Trainer , designation\n",
      "HCL Infosystems Limited (CDC) , organization\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      " ENTITIES : \n",
      "\n",
      "python developer , designation\n",
      "Brio Technologies Pvt Ltd Hyderabad , organization\n",
      "October 2018 to till now , date\n",
      "Python developer , designation\n",
      "Hallmark Solutions, vizag (start-up) , organization\n",
      "Jul 2018 to Aug 31 , date\n",
      "Python Developer , designation\n",
      "Citimedia Global Solutions Pvt Ltd , organization\n",
      "Oct 2016-jul 2018 , date\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      " ENTITIES : \n",
      "\n",
      "JAN 2020 – PRESENT , date\n",
      "DATA ANALYST , designation\n",
      "WEBMAAZIX SOLUTIONS PVT LTD , organization\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      " ENTITIES : \n",
      "\n",
      "Data scientist – Intern , designation\n",
      "Innodatatics , organization\n",
      "December 2021 - Present , date\n",
      "Associate - Enrollment , designation\n",
      "Legato Health Technologies , organization\n",
      "March 2020 - September 2021 , date\n",
      "Pharma Benefit Analyst (QA) , designation\n",
      "Optum Global Solutions , organization\n",
      "July 2017 - December 2019 , date\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      " ENTITIES : \n",
      "\n",
      "Senior Data Scientist , designation\n",
      "Capgemini , organization\n",
      "2020 - Ongoing , date\n",
      "Data Scientist , designation\n",
      "IBM , organization\n",
      "2018 - 2020 , date\n",
      "Entry-Level Data Scientist , designation\n",
      "ResultsCX , organization\n",
      "2016- 2018 , date\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      " ENTITIES : \n",
      "\n",
      "Data Analyst , designation\n",
      "PROMAESTRO TECHSOURCE Pvt. , organization\n",
      "Sept 2019 to Till date , date\n",
      "Software Engineer , designation\n",
      "Magna InfoTech (A Subsidiary of Quess Corp Limited) , date\n",
      "April 2019 to Aug 2019 , date\n",
      "LTE Test Engineer , designation\n",
      "Pentagram Infotech Pvt. , organization\n",
      "May 2014 to Oct 2017 , date\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      " ENTITIES : \n",
      "\n",
      "TECH MAHINDRA , organization\n",
      "DEC 2016 – PRESENT , date\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      " ENTITIES : \n",
      "\n",
      "TEKOPTIMIZE SOFTWARE INDIA Pvt. , organization\n",
      "17th July 2017 to Present , date\n",
      "Data Scientist , designation\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      " ENTITIES : \n",
      "\n",
      "Machine Learning Engineer , designation\n",
      "PPC Minds Consulting , designation\n",
      "Dec 2017 – Present , organization\n",
      "Research Engineer , designation\n",
      "Openmined , organization\n",
      "October 2019 – Present , date\n",
      "Programmer Analyst (Quality Analyst) , designation\n",
      "Cognizant Technology Solutions , organization\n",
      "May 2015- , date\n",
      "Customer Service Agent , designation\n",
      "Amazon , organization\n",
      "June 2015 – Aug 2015 , date\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      " ENTITIES : \n",
      "\n",
      "Data Scientist Consultant , designation\n",
      "Rubixe , organization\n",
      "11/2020 - Present , date\n",
      "R&D Engineer , designation\n",
      "Rolls Royce , organization\n",
      "08/2019 - 07/2020 , date\n",
      "Engineer , designation\n",
      "QuEST , organization\n",
      "01/2017 - 10/2020 , date\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      " ENTITIES : \n",
      "\n",
      "Codesets IT Solutions (INDIA) Pvt Ltd. , organization\n",
      "Jan 2019 , date\n",
      "Till Date , date\n",
      "Data Scientist , designation\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      " ENTITIES : \n",
      "\n",
      "Cyient , organization\n",
      "Junior Gis , designation\n",
      "2013 , date\n",
      "2014 , date\n",
      "RAMTECH SOFTWARE SOLUTIONS , organization\n",
      "GIs Engineer , designation\n",
      "Tata Consultancy Services , organization\n",
      "Gis engineer , designation\n",
      "15-10-2017 , date\n",
      "20-03-2019 , date\n",
      "20-03-2020 , date\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      " ENTITIES : \n",
      "\n",
      "Senior Associate , designation\n",
      "Wipro , organization\n",
      "Nov 2016 , date\n",
      "Jan 2020 , date\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      " ENTITIES : \n",
      "\n",
      "JUNE 2019 , date\n",
      "PRESENT , date\n",
      "Data Science Engineer , designation\n",
      "Gramener, Hyderabad , organization\n",
      "FEBRUARY 2016 , date\n",
      "MAY 2019 , date\n",
      "Programmer , designation\n",
      "Cognosia Institute Private Ltd, Hyderabad , organization\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      " ENTITIES : \n",
      "\n",
      "TATA Consultancy Services , organization\n",
      "Machine Learning Engineer , designation\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      " ENTITIES : \n",
      "\n",
      "Data Analyst , designation\n",
      "SYS NOV technologies PVT LTD , organization\n",
      "Sr. , designation\n",
      "Synchrony International service PVT ltd , organization\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      " ENTITIES : \n",
      "\n",
      "07/2018 , date\n",
      "Present , date\n",
      "Data Scientist , designation\n",
      "Wipro , organization\n",
      "Machine Learning Engineer , designation\n",
      "Wipro , organization\n",
      "Data Scientist , designation\n",
      "Wipro , organization\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      " ENTITIES : \n",
      "\n",
      "Data Scientist , designation\n",
      "FIRST TECH Consulting , organization\n",
      "Jan 2018 , date\n",
      "Present , date\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      " ENTITIES : \n",
      "\n",
      "Data Scientist , designation\n",
      "Optm Private ltd , organization\n",
      "till date , date\n",
      "Data Scientist , designation\n",
      "Alignity. , organization\n",
      "Aug 2019 , date\n",
      "Aug 2021. , date\n",
      "Data Scientist , designation\n",
      "Yagnum , organization\n",
      "Jul 2017 , date\n",
      "Aug 2019. , date\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      " ENTITIES : \n",
      "\n",
      "Data Scientist , designation\n",
      "TCS Hyderabad , organization\n",
      "02/01/2018 , date\n",
      "till date , date\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      " ENTITIES : \n",
      "\n",
      "Software Engineer , designation\n",
      "Jan ’16 , date\n",
      "Present , date\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      " ENTITIES : \n",
      "\n",
      "Senior Software Engineer , designation\n",
      "Altran , organization\n",
      "Feb 2019 , date\n",
      "Present , date\n",
      "Software Engineer , designation\n",
      "CES Limited , organization\n",
      "Dec 2017 , date\n",
      "Dec 2018 , date\n",
      "Software Engineer , designation\n",
      "Mobigesture , organization\n",
      "Aug 2015 , date\n",
      "Dec 2017 , date\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      " ENTITIES : \n",
      "\n",
      "Software Engineer , designation\n",
      "Reliance Jio , organization\n",
      "Aug 2020 , date\n",
      "Present , date\n",
      "Software Engineer , designation\n",
      "Tata Consultancy Services , organization\n",
      "Nov 2016 , date\n",
      "Jul 2020 , date\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      " ENTITIES : \n",
      "\n",
      "Python Developer , designation\n",
      "Optum Global Solutions , organization\n",
      "Sep-2016 , date\n",
      "Oct-2019 , date\n",
      "Python Developer , designation\n",
      "Nov-2019 , date\n",
      "July-2020. , date\n",
      "\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " ENTITIES : \n",
      "\n",
      "Software Engineer , designation\n",
      "Pega Systems , organization\n",
      "07/2021 , date\n",
      "Present , date\n",
      "Machine Learning Engineer , designation\n",
      "ADP India , organization\n",
      "03/2017 , date\n",
      "07/2019 , date\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      " ENTITIES : \n",
      "\n",
      "Data analytics , designation\n",
      "DATA ANALYST , designation\n",
      "ESMOB Technolgies Pvt Ltd. , organization\n",
      "April 2020 , date\n",
      "till date , date\n",
      "DATA ASSOCIATE , designation\n",
      "ESMOB Technologies Pvt Ltd , organization\n",
      "July 2018 , date\n",
      "March 2020. , date\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      " ENTITIES : \n",
      "\n",
      "Software Engineer , designation\n",
      "PERITO CYBER MANAGEMENT PVT LTD , organization\n",
      "Feb 2017 , date\n",
      "till Date , date\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      " ENTITIES : \n",
      "\n",
      "Software Developer , designation\n",
      "Andhra Pradesh State Skill Development Corporation , organization\n",
      "May 2015 , date\n",
      "till the date , date\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      " ENTITIES : \n",
      "\n",
      "Data Scientist , designation\n",
      "Senior Software Engineer , designation\n",
      "ValueLabs , organization\n",
      "August 2020 , date\n",
      "Present , date\n",
      "Software Engineer , designation\n",
      "ValueLabs , organization\n",
      "July 2019 , date\n",
      "July 2020 , date\n",
      "Ardent Computech Private Limited , organization\n",
      "Machine Learning Intern , designation\n",
      "May 2018 , date\n",
      "Aug 2018 , date\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      " ENTITIES : \n",
      "\n",
      "Accenture Services Pvt. , organization\n",
      "Associate Data Scientist , designation\n",
      "May 2018 , date\n",
      "Jan 2021. , date\n",
      "CDK Global Pvt. , organization\n",
      "Data Scientist , designation\n",
      "Jan 2021 , date\n",
      "Present. , date\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      " ENTITIES : \n",
      "\n",
      "Norm Software , organization\n",
      "Feb 2020 , date\n",
      "till date , date\n",
      "Software Engineer , designation\n",
      "Mandali Software Solution Pvt Ltd , organization\n",
      "Aug 2016 , date\n",
      "Jan 2020 , date\n",
      "Software Engineer , designation\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      " ENTITIES : \n",
      "\n",
      "Sysark Datasol Pvt. , organization\n",
      "Jan 2019 , date\n",
      "Till Date , date\n",
      "Data Scientist , designation\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      " ENTITIES : \n",
      "\n",
      "May 2021 , date\n",
      "Till Date , date\n",
      "Feb 2020 , date\n",
      "ML Engineer , designation\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      " ENTITIES : \n",
      "\n",
      "IFS India Marcantile Pvt. , organization\n",
      "March 2021 , date\n",
      "Present , date\n",
      "Data Scientist , designation\n",
      "IFS India Marcantile Pvt. , organization\n",
      "May 2020 , date\n",
      "March 2021 , date\n",
      "Data Scientist , designation\n",
      "IFS India Marcantile Pvt , organization\n",
      "June 2019 , date\n",
      "April 2020 , date\n",
      "Data Scientist , designation\n",
      "IFS India Marcantile Pvt. , organization\n",
      "Dec 2018 , date\n",
      "May 2019 , date\n",
      "Data Scientist , designation\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      " ENTITIES : \n",
      "\n",
      "December 2018 , date\n",
      "Till Date , date\n",
      "Data Scientist , designation\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      " ENTITIES : \n",
      "\n",
      "Data Analyst , designation\n",
      "ESMOB TECHNOLOGIES PRIVATE LIMITED , organization\n",
      "Oct 2019 , date\n",
      "Till Date , date\n",
      "HR Executive , designation\n",
      "Lejara Global IT Solutions Pvt. , organization\n",
      "July 2017 , date\n",
      "Sep 2019 , date\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      " ENTITIES : \n",
      "\n",
      "TechMahindra ltd , organization\n",
      "Software Engineer , designation\n",
      "Feb 2017 , date\n",
      "Till date , date\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      " ENTITIES : \n",
      "\n",
      "Tata Consultancy Services , organization\n",
      "Machine Learning Engineer , designation\n",
      "Jan 2019 , date\n",
      "Till Date , date\n",
      "Oracle Database Administrator , designation\n",
      "July 2018 , date\n",
      "Dec 2018 , date\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      " ENTITIES : \n",
      "\n",
      "IVEOND Consulting Pvt Ltd , organization\n",
      "Data Scientist , designation\n",
      "1/09/2021 , date\n",
      "current Date , date\n",
      "Synerg Technology (India) , organization\n",
      "Junior AI Developer , designation\n",
      "14/09/2020 , date\n",
      "29/08/2021 , date\n",
      "Mandate Logistics Pvt Ltd , organization\n",
      "Data Scientist , designation\n",
      "07/08/2019 , date\n",
      "07/09/2020 , date\n",
      "Data Scientist (Intern) , designation\n",
      "02/2018 , date\n",
      "01/2019 , date\n",
      "Feedback180 Co. Ltd , organization\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      " ENTITIES : \n",
      "\n",
      "Data Scientist , designation\n",
      "Tech Mahindra , organization\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('./models')\n",
    "doc = nlp\n",
    "\n",
    "values = {}\n",
    "org = []\n",
    "date = []\n",
    "des = []\n",
    "\n",
    "list1 = []\n",
    "list2 = []\n",
    "\n",
    "for k in range(0, 49):\n",
    "    print(\"\\n\\n--------------------------------------------------\")\n",
    "    doc = nlp(json_data.data[k]['text'])\n",
    "    print(\"\\n\\n\",\"ENTITIES : \\n\")\n",
    "    for ent in doc.ents:      \n",
    "        print(ent.text,\",\",ent.label_)\n",
    "#         value = ent.text + \",\" + ent.label_\n",
    "#         list1.append(value)\n",
    "# list2.append(list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sysark Datasol Pvt. , organization\n",
      "Jan 2019 , date\n",
      "Till Date , date\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"3+ years of Experience in Sysark Datasol Pvt. Ltd. (Jan 2019 - Till Date)\"\"\"\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "for ent in doc.ents:\n",
    "     print(ent.text,\",\",ent.label_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k in range(0, 4):\n",
    "#     doc = nlp(json_data.data[k]['text'])\n",
    "#     print(doc)\n",
    "#     print(\"===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "details = {\"information\" : list2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data Scientist,designation'"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['information'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Scientist,designation',\n",
       " 'TCS,organization',\n",
       " '1st July 2019to till date,date',\n",
       " 'Applications Engineer,designation',\n",
       " 'Oracle India Pvt ltd,organization',\n",
       " 'April 2018 to present,date',\n",
       " 'Associate Projects,designation',\n",
       " 'Cognizant Technology Solutions,organization',\n",
       " 'August 2014 to April 2018,date',\n",
       " 'Software Engineer,designation',\n",
       " 'Tech Mahindra ltd,organization',\n",
       " 'August 2013 to May 2014.,date',\n",
       " 'Hyundai,Hyderabad,organization',\n",
       " 'Sep 2020 –,date',\n",
       " 'Data Analyst/Data Scientist,designation',\n",
       " 'CMS Energy, Hyderabad,organization',\n",
       " 'Apr 2018 – Aug 2020,date',\n",
       " 'Data Analyst/Data Scientist,organization',\n",
       " 'Bank of the West, Hyderabad,organization',\n",
       " 'Aug 2016 – Mar 2018,date',\n",
       " 'Data Analyst / Data Scientist,designation',\n",
       " 'COLLABERA TECHNOLOGIES PRIVATE LIMITED,organization',\n",
       " 'Data Scientist,designation',\n",
       " 'May 2021 to present,date',\n",
       " 'SOFT CONNEX TECHNOLOGIES PRIVATE LIMITED,organization',\n",
       " 'Data Analyst,designation',\n",
       " 'December 2017 to April 2021,date',\n",
       " 'Software Engineer,designation',\n",
       " 'October 2017 to November 2017,date',\n",
       " 'Senior Process Executive,designation',\n",
       " 'Infosys,organization',\n",
       " '07/2017 - Present,date',\n",
       " 'Data Analyst - Internship,designation',\n",
       " '06/2021 - 08/2021,date',\n",
       " 'Data Analyst,designation',\n",
       " 'Global Logic,organization',\n",
       " 'Intern,designation',\n",
       " 'Clossus360,organization',\n",
       " '09/2014 - 05/2015,date',\n",
       " 'Synechron,organization',\n",
       " 'Data Scientist,designation',\n",
       " 'February 2020 to till Date,date',\n",
       " 'Decision minds,organization',\n",
       " 'Junior Data scientist,designation',\n",
       " 'March 2020 – Present,date',\n",
       " 'Commonwealth Bank of Australia,organization',\n",
       " 'Data Scientist,designation',\n",
       " 'Jan 2021-Present,date',\n",
       " 'Velankani Communications,organization',\n",
       " 'Data Scientist,designation',\n",
       " 'July 2020-Dec-2020,date',\n",
       " 'Tata Consultancy Services,organization',\n",
       " 'Data Scientist,designation',\n",
       " 'July 2016-June 2020,date',\n",
       " 'NOV’16 – OCT’17,date',\n",
       " 'Tech Mahindra,organization',\n",
       " 'Associate Software Engineer.,designation',\n",
       " 'AUG’18 – OCT’20,date',\n",
       " 'Vitech Systems Asia Pvt. Ltd,organization',\n",
       " 'Associate Developer,designation',\n",
       " 'NOV’20 – Present,date',\n",
       " 'KPMG,organization',\n",
       " 'Data Scientist.,designation',\n",
       " 'September 2020 –,date',\n",
       " 'Python Developer,designation',\n",
       " 'June 2018 – August 2020,date',\n",
       " 'Python Developer,designation',\n",
       " 'IEM (Development Section),organization',\n",
       " 'Jan 2014 – May 2018,date',\n",
       " 'Assistant Professor,designation',\n",
       " 'IEM (Academic Section),organization',\n",
       " 'Jun 2012 – Dec 2013,date',\n",
       " 'System Administrator and Lecturer,designation',\n",
       " 'May 2011 – Mar 2012,date',\n",
       " 'IT Executive,designation',\n",
       " 'HIND-FAME Limited,organization',\n",
       " 'Nov 2008 – Oct 2009,date',\n",
       " 'Technical Trainer,designation',\n",
       " 'HCL Infosystems Limited (CDC),organization',\n",
       " 'python developer,designation',\n",
       " 'Brio Technologies Pvt Ltd Hyderabad,organization',\n",
       " 'October 2018 to till now,date',\n",
       " 'Python developer,designation',\n",
       " 'Hallmark Solutions, vizag (start-up),organization',\n",
       " 'Jul 2018 to Aug 31,date',\n",
       " 'Python Developer,designation',\n",
       " 'Citimedia Global Solutions Pvt Ltd,organization',\n",
       " 'Oct 2016-jul 2018,date',\n",
       " 'JAN 2020 – PRESENT,date',\n",
       " 'DATA ANALYST,designation',\n",
       " 'WEBMAAZIX SOLUTIONS PVT LTD,organization',\n",
       " 'Data scientist – Intern,designation',\n",
       " 'Innodatatics,organization',\n",
       " 'December 2021 - Present,date',\n",
       " 'Associate - Enrollment,designation',\n",
       " 'Legato Health Technologies,organization',\n",
       " 'March 2020 - September 2021,date',\n",
       " 'Pharma Benefit Analyst (QA),designation',\n",
       " 'Optum Global Solutions,organization',\n",
       " 'July 2017 - December 2019,date',\n",
       " 'Senior Data Scientist,designation',\n",
       " 'Capgemini,organization',\n",
       " '2020 - Ongoing,date',\n",
       " 'Data Scientist,designation',\n",
       " 'IBM,organization',\n",
       " '2018 - 2020,date',\n",
       " 'Entry-Level Data Scientist,designation',\n",
       " 'ResultsCX,organization',\n",
       " '2016- 2018,date',\n",
       " 'Data Analyst,designation',\n",
       " 'PROMAESTRO TECHSOURCE Pvt.,organization',\n",
       " 'Sept 2019 to Till date,date',\n",
       " 'Software Engineer,designation',\n",
       " 'Magna InfoTech (A Subsidiary of Quess Corp Limited),date',\n",
       " 'April 2019 to Aug 2019,date',\n",
       " 'LTE Test Engineer,designation',\n",
       " 'Pentagram Infotech Pvt.,organization',\n",
       " 'May 2014 to Oct 2017,date',\n",
       " 'TECH MAHINDRA,organization',\n",
       " 'DEC 2016 – PRESENT,date',\n",
       " 'TEKOPTIMIZE SOFTWARE INDIA Pvt.,organization',\n",
       " '17th July 2017 to Present,date',\n",
       " 'Data Scientist,designation',\n",
       " 'Machine Learning Engineer,designation',\n",
       " 'PPC Minds Consulting,designation',\n",
       " 'Dec 2017 – Present,organization',\n",
       " 'Research Engineer,designation',\n",
       " 'Openmined,organization',\n",
       " 'October 2019 – Present,date',\n",
       " 'Programmer Analyst (Quality Analyst),designation',\n",
       " 'Cognizant Technology Solutions,organization',\n",
       " 'May 2015-,date',\n",
       " 'Customer Service Agent,designation',\n",
       " 'Amazon,organization',\n",
       " 'June 2015 – Aug 2015,date',\n",
       " 'Data Scientist Consultant,designation',\n",
       " 'Rubixe,organization',\n",
       " '11/2020 - Present,date',\n",
       " 'R&D Engineer,designation',\n",
       " 'Rolls Royce,organization',\n",
       " '08/2019 - 07/2020,date',\n",
       " 'Engineer,designation',\n",
       " 'QuEST,organization',\n",
       " '01/2017 - 10/2020,date',\n",
       " 'Codesets IT Solutions (INDIA) Pvt Ltd.,organization',\n",
       " 'Jan 2019,date',\n",
       " 'Till Date,date',\n",
       " 'Data Scientist,designation',\n",
       " 'Cyient,organization',\n",
       " 'Junior Gis,designation',\n",
       " '2013,date',\n",
       " '2014,date',\n",
       " 'RAMTECH SOFTWARE SOLUTIONS,organization',\n",
       " 'GIs Engineer,designation',\n",
       " 'Tata Consultancy Services,organization',\n",
       " 'Gis engineer,designation',\n",
       " '15-10-2017,date',\n",
       " '20-03-2019,date',\n",
       " '20-03-2020,date',\n",
       " 'Senior Associate,designation',\n",
       " 'Wipro,organization',\n",
       " 'Nov 2016,date',\n",
       " 'Jan 2020,date',\n",
       " 'JUNE 2019,date',\n",
       " 'PRESENT,date',\n",
       " 'Data Science Engineer,designation',\n",
       " 'Gramener, Hyderabad,organization',\n",
       " 'FEBRUARY 2016,date',\n",
       " 'MAY 2019,date',\n",
       " 'Programmer,designation',\n",
       " 'Cognosia Institute Private Ltd, Hyderabad,organization',\n",
       " 'TATA Consultancy Services,organization',\n",
       " 'Machine Learning Engineer,designation',\n",
       " 'Data Analyst,designation',\n",
       " 'SYS NOV technologies PVT LTD,organization',\n",
       " 'Sr.,designation',\n",
       " 'Synchrony International service PVT ltd,organization',\n",
       " '07/2018,date',\n",
       " 'Present,date',\n",
       " 'Data Scientist,designation',\n",
       " 'Wipro,organization',\n",
       " 'Machine Learning Engineer,designation',\n",
       " 'Wipro,organization',\n",
       " 'Data Scientist,designation',\n",
       " 'Wipro,organization',\n",
       " 'Data Scientist,designation',\n",
       " 'FIRST TECH Consulting,organization',\n",
       " 'Jan 2018,date',\n",
       " 'Present,date',\n",
       " 'Data Scientist,designation',\n",
       " 'Optm Private ltd,organization',\n",
       " 'till date,date',\n",
       " 'Data Scientist,designation',\n",
       " 'Alignity.,organization',\n",
       " 'Aug 2019,date',\n",
       " 'Aug 2021.,date',\n",
       " 'Data Scientist,designation',\n",
       " 'Yagnum,organization',\n",
       " 'Jul 2017,date',\n",
       " 'Aug 2019.,date',\n",
       " 'Data Scientist,designation',\n",
       " 'TCS Hyderabad,organization',\n",
       " '02/01/2018,date',\n",
       " 'till date,date',\n",
       " 'Software Engineer,designation',\n",
       " 'Jan ’16,date',\n",
       " 'Present,date',\n",
       " 'Senior Software Engineer,designation',\n",
       " 'Altran,organization',\n",
       " 'Feb 2019,date',\n",
       " 'Present,date',\n",
       " 'Software Engineer,designation',\n",
       " 'CES Limited,organization',\n",
       " 'Dec 2017,date',\n",
       " 'Dec 2018,date',\n",
       " 'Software Engineer,designation',\n",
       " 'Mobigesture,organization',\n",
       " 'Aug 2015,date',\n",
       " 'Dec 2017,date',\n",
       " 'Software Engineer,designation',\n",
       " 'Reliance Jio,organization',\n",
       " 'Aug 2020,date',\n",
       " 'Present,date',\n",
       " 'Software Engineer,designation',\n",
       " 'Tata Consultancy Services,organization',\n",
       " 'Nov 2016,date',\n",
       " 'Jul 2020,date',\n",
       " 'Python Developer,designation',\n",
       " 'Optum Global Solutions,organization',\n",
       " 'Sep-2016,date',\n",
       " 'Oct-2019,date',\n",
       " 'Python Developer,designation',\n",
       " 'Nov-2019,date',\n",
       " 'July-2020.,date',\n",
       " 'Software Engineer,designation',\n",
       " 'Pega Systems,organization',\n",
       " '07/2021,date',\n",
       " 'Present,date',\n",
       " 'Machine Learning Engineer,designation',\n",
       " 'ADP India,organization',\n",
       " '03/2017,date',\n",
       " '07/2019,date',\n",
       " 'Data analytics,designation',\n",
       " 'DATA ANALYST,designation',\n",
       " 'ESMOB Technolgies Pvt Ltd.,organization',\n",
       " 'April 2020,date',\n",
       " 'till date,date',\n",
       " 'DATA ASSOCIATE,designation',\n",
       " 'ESMOB Technologies Pvt Ltd,organization',\n",
       " 'July 2018,date',\n",
       " 'March 2020.,date',\n",
       " 'Software Engineer,designation',\n",
       " 'PERITO CYBER MANAGEMENT PVT LTD,organization',\n",
       " 'Feb 2017,date',\n",
       " 'till Date,date',\n",
       " 'Software Developer,designation',\n",
       " 'Andhra Pradesh State Skill Development Corporation,organization',\n",
       " 'May 2015,date',\n",
       " 'till the date,date',\n",
       " 'Data Scientist,designation',\n",
       " 'Senior Software Engineer,designation',\n",
       " 'ValueLabs,organization',\n",
       " 'August 2020,date',\n",
       " 'Present,date',\n",
       " 'Software Engineer,designation',\n",
       " 'ValueLabs,organization',\n",
       " 'July 2019,date',\n",
       " 'July 2020,date',\n",
       " 'Ardent Computech Private Limited,organization',\n",
       " 'Machine Learning Intern,designation',\n",
       " 'May 2018,date',\n",
       " 'Aug 2018,date',\n",
       " 'Accenture Services Pvt.,organization',\n",
       " 'Associate Data Scientist,designation',\n",
       " 'May 2018,date',\n",
       " 'Jan 2021.,date',\n",
       " 'CDK Global Pvt.,organization',\n",
       " 'Data Scientist,designation',\n",
       " 'Jan 2021,date',\n",
       " 'Present.,date',\n",
       " 'Norm Software,organization',\n",
       " 'Feb 2020,date',\n",
       " 'till date,date',\n",
       " 'Software Engineer,designation',\n",
       " 'Mandali Software Solution Pvt Ltd,organization',\n",
       " 'Aug 2016,date',\n",
       " 'Jan 2020,date',\n",
       " 'Software Engineer,designation',\n",
       " 'Sysark Datasol Pvt.,organization',\n",
       " 'Jan 2019,date',\n",
       " 'Till Date,date',\n",
       " 'Data Scientist,designation',\n",
       " 'May 2021,date',\n",
       " 'Till Date,date',\n",
       " 'Feb 2020,date',\n",
       " 'ML Engineer,designation',\n",
       " 'IFS India Marcantile Pvt.,organization',\n",
       " 'March 2021,date',\n",
       " 'Present,date',\n",
       " 'Data Scientist,designation',\n",
       " 'IFS India Marcantile Pvt.,organization',\n",
       " 'May 2020,date',\n",
       " 'March 2021,date',\n",
       " 'Data Scientist,designation',\n",
       " 'IFS India Marcantile Pvt,organization',\n",
       " 'June 2019,date',\n",
       " 'April 2020,date',\n",
       " 'Data Scientist,designation',\n",
       " 'IFS India Marcantile Pvt.,organization',\n",
       " 'Dec 2018,date',\n",
       " 'May 2019,date',\n",
       " 'Data Scientist,designation',\n",
       " 'December 2018,date',\n",
       " 'Till Date,date',\n",
       " 'Data Scientist,designation',\n",
       " 'Data Analyst,designation',\n",
       " 'ESMOB TECHNOLOGIES PRIVATE LIMITED,organization',\n",
       " 'Oct 2019,date',\n",
       " 'Till Date,date',\n",
       " 'HR Executive,designation',\n",
       " 'Lejara Global IT Solutions Pvt.,organization',\n",
       " 'July 2017,date',\n",
       " 'Sep 2019,date',\n",
       " 'TechMahindra ltd,organization',\n",
       " 'Software Engineer,designation',\n",
       " 'Feb 2017,date',\n",
       " 'Till date,date',\n",
       " 'Tata Consultancy Services,organization',\n",
       " 'Machine Learning Engineer,designation',\n",
       " 'Jan 2019,date',\n",
       " 'Till Date,date',\n",
       " 'Oracle Database Administrator,designation',\n",
       " 'July 2018,date',\n",
       " 'Dec 2018,date',\n",
       " 'IVEOND Consulting Pvt Ltd,organization',\n",
       " 'Data Scientist,designation',\n",
       " '1/09/2021,date',\n",
       " 'current Date,date',\n",
       " 'Synerg Technology (India),organization',\n",
       " 'Junior AI Developer,designation',\n",
       " '14/09/2020,date',\n",
       " '29/08/2021,date',\n",
       " 'Mandate Logistics Pvt Ltd,organization',\n",
       " 'Data Scientist,designation',\n",
       " '07/08/2019,date',\n",
       " '07/09/2020,date',\n",
       " 'Data Scientist (Intern),designation',\n",
       " '02/2018,date',\n",
       " '01/2019,date',\n",
       " 'Feedback180 Co. Ltd,organization',\n",
       " 'Data Scientist,designation',\n",
       " 'Tech Mahindra,organization']"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['information'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(des)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"3+ years of Experience in Sysark Datasol Pvt. Ltd. (Jan 2019-Till Date)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3+ years of Experience in Sysark Datasol Pvt. Ltd. (Jan 2019-Till Date)\n"
     ]
    }
   ],
   "source": [
    "print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3+ years , total exp\n",
      "Sysark Datasol Pvt. , companies\n",
      "Ltd. , algorithms\n",
      "Jan 2019 , start date\n",
      "Till Date , end date\n"
     ]
    }
   ],
   "source": [
    "for ent in doc.ents:\n",
    "#     if ent.label == \"\"\n",
    "     print(ent.text,\",\",ent.label_)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "designation = []\n",
    "organization = []\n",
    "date = []\n",
    "\n",
    "to_count = 0\n",
    "us_count = 0\n",
    "x\n",
    "for ent in doc.ents:\n",
    "    if ent.label_ == \"designation\":\n",
    "        designation.append(ent.text)\n",
    "    elif ent.label_ == \"organization\":\n",
    "        organization.append(ent.text)\n",
    "    else:\n",
    "        date.append(ent.text)  \n",
    "\n",
    "    df = pd.DataFrame([designation,organization,date]).T\n",
    "    df.columns = ['designation','organization','date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>designation</th>\n",
       "      <th>organization</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Optm Private ltd</td>\n",
       "      <td>Sep 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Alignity.</td>\n",
       "      <td>till date</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Yagnum</td>\n",
       "      <td>Aug 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Aug 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Jul 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Aug 2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      designation      organization       date\n",
       "0  Data Scientist  Optm Private ltd   Sep 2020\n",
       "1  Data Scientist         Alignity.  till date\n",
       "2  Data Scientist            Yagnum   Aug 2019\n",
       "3            None              None   Aug 2021\n",
       "4            None              None   Jul 2017\n",
       "5            None              None   Aug 2019"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame(columns = ['desg','orgs','date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(['abc',c_desg, orgs, date]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data Scientist'"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_desg = df.designation.tolist()[1]\n",
    "c_desg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Optm Private ltd', 'Alignity.', 'Yagnum', None, None, None]"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orgs = df.organization.tolist()\n",
    "orgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame(columns = ['name','desg','orgs', 'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(['res1', c_desg, orgs, date]).T\n",
    "df1.columns = ['name','desg','orgs', 'date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Optm Private ltd', 'Alignity.', 'Yagnum', None, None, None]"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['orgs'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat([final_df,df1],axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>desg</th>\n",
       "      <th>orgs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>res1</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>[Optm Private ltd, Alignity., Yagnum]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   name            desg                                   orgs\n",
       "0  res1  Data Scientist  [Optm Private ltd, Alignity., Yagnum]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "desig = []\n",
    "organ = []\n",
    "dat = []\n",
    "\n",
    "to_count = 0\n",
    "us_count = 0\n",
    "\n",
    "for ent in doc.ents:\n",
    "    if ent.label_ == \"designation\":\n",
    "        desig.append(ent.text)\n",
    "    elif ent.label_ == \"organization\":\n",
    "        organ.append(ent.text)\n",
    "    else:\n",
    "        dat.append(ent.text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "da = []\n",
    "\n",
    "if len(org) < len(dat):\n",
    "    for i in range(0, len(dat)-1):\n",
    "        if \"to\" or \"-\" not in dat:\n",
    "            da.append(dat[i]+\" to \" + dat[i+1])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sep 2020', 'till date', 'Aug 2019', 'Aug 2021', 'Jul 2017', 'Aug 2019']"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  1\n",
      "1  2\n",
      "2  3\n",
      "3  4\n",
      "4  5\n"
     ]
    }
   ],
   "source": [
    "a = [1,2,3,4,5,6]\n",
    "for i in range(len(a)):\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sep 2020 to till date\n",
      "till date to Aug 2019\n",
      "Aug 2019 to Aug 2021\n",
      "Aug 2021 to Jul 2017\n",
      "Jul 2017 to Aug 2019\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(dat)-1):\n",
    "    if i<=len(dat):\n",
    "        if dat[i] != dat[i-1]:\n",
    "            print(dat[i],\"to\", dat[i+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(r'F:\\projects\\RR\\code\\RNER\\models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = r\"F:\\projects\\RR\\Datasets\\sample_resumes\\text_resumes\\abinash cv1.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "\n",
    "with open(file, \"r\",encoding='utf-8') as fp:\n",
    "    text = ''.join(fp.readlines())\n",
    "    texts.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = ''.join(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nAbinash Sahu \\n                                                                     \\n \\nEmail ID:abinashgcs@gmail.com                Cell: +91-7008460530 \\n \\n \\nCareer Objective \\n \\nHighly motivated individual with a strong track record of performance in handling relationship \\nmanagement activities to identify and define business requirements, and translate business needs \\ninto complex models. Competent at identifying different data sources and providing associated data \\nmodelling and data visualization. \\n \\n                                                                       Key Skills \\n \\n| Python | Advance Predictive modeling and designing drilldown analysis for business insights \\n|Statistical modeling  |Machine Learning Algorithms| EDA | Natural Language Processing |Text \\nmining |Text Class|My SQL| Credit Risk Analysis and Project Management  | Client management \\nand cross functional project handling | GIT  \\n \\nQualification Summary \\n \\n  Analytical, enthusiastic and innovative Data Science Lead with  3+ years of IT experience in the \\ndifferent areas of Data Science, Machine Learning and Automation. \\n  Deft at undertaking various statistical methods and testing processes such as hypothesis testing, \\nLinear regression, Logistic regression, Clustering, Decision Trees, Random Forest and Natural \\nLanguage Processing.  \\n \\n  Pragmatic  exposure  in  data  ingestion  and  cleaning  using  Python  Programming. Thorough \\nknowledge of Data warehousing and Data mining concepts. \\n \\n  Sound knowledge of drawing insights through predictive analysis and data visualization, to drive \\nbetter decision making through the use of various statistical modelling techniques.  \\n \\n  Experienced in all phases of data analysis spanning definition and analysis of questions with \\nrespect to available dasta & resources, overview of data &  assessment of data quality, selection of \\nappropriate models & statistical tests and presentation of results \\n \\n  Leveraging skill in importing, cleaning, transforming, validating or modelling data with the purpose \\nof understanding or making conclusions from the data for decision making purposes. \\n \\n  Good at SQL commands (DDL, DML, DCL, Joins, sub queries) and SQL functions. \\n \\nTechnical Skills \\n \\n \\n  Python - Developed various regression and classification models of ML using pandas, numpy, scikit \\nlearn etc, and visualization using Seaborn and MatPlotlib libraries. Good experience in validating \\nmodels using Cross validation, confusion matrix, ROC curve etc. \\n  Statistics- Strong understanding on applied Statistics and advance statistical analysis.   Machine Learning and AI– Strong working knowledge of various ML regression and classification \\nalgorithms such as Linear and logistic regression, Decision tree, Random forest, SVM,kNN,Naïve-\\nBayes,XG-Boost etc. Strong knowledge of hypothesis testing. \\n  SQL– Good knowledge on database management and query writing skills in SQL and Access. \\nStatements and clauses, Entity and attribute relationships, Joins, views, pivot and un-pivot, case and \\nwhen statement, ranking and row order and store procedures etc. \\n \\n \\n \\n \\nWork Experience \\n\\uf0b7  3+ years of Experience in Sysark Datasol Pvt. Ltd. (Jan 2019-Till Date) \\n \\n \\n Mar 2021 till Sep 2021 \\n \\nProject : Credit Risk Management \\nDesignation : Data Scientist  \\nTools & Techologies used : Python,EDA,Statistical Analysis,Machine Learning Models,Cross Validation. \\nObjective: \\nThe main objective of this project is to understand credit risk management which is a practice of mitigating \\nlosses by understanding the adequacy of a bank’s capital and loan loss reserves at any given time, a \\nprocess that has long been a challenge for financial institutions. \\nEffective credit risk management is to gain a complete understanding of a bank’s overall credit risk by \\nviewing risk at the individual, customer and portfolio levels. \\n \\nResponsibility: \\n\\uf0b7  To understand the Business problem and interact with the client on regular basis to get more and \\ndeep insight of the data shared by the client. \\n\\uf0b7  Better model management that spans the entire modelling life cycle. \\n\\uf0b7  Data visualization capabilities and business intelligence tools that get important information into \\nthe hands of those who need it, when they need it. \\n\\uf0b7  To draw the insights from the data and develop a predictive model which will help in categorizing \\nthe individual customer and sector of the bank efficiently. \\n\\uf0b7  To do the variable selection which are important in developing predictive model with good \\naccuracy.  \\n\\uf0b7  Prepare Origination and Performance reporting to create multiple dashboards for drill down \\nanalysis and specific KPI metrics. \\n\\uf0b7  Design data architecture and solve complex data integrity issues.  \\n\\uf0b7  Design various charts to explain the trend and perforce of portfolios over the period of time. \\n\\uf0b7  Create drill down analysis in Tableau. \\n \\n      Dec2019-Nov 2020 \\nProject :  Sentiment Analysis \\nSentiment Analysis for Air Purification Market: The client in consumer electronics domain was looking \\nfor insights into a fast growing product in Indian Consumer Market – Air Purifiers. The insights project was \\ndriven by Sentiment Analysis of social media data  (i.e. Tweets /Comments / Status Updates/Product \\nreviews) using Python. The project also included a paid review classifier which would flag reviews as paid \\nor genuine. \\n  \\nObjective: The main objective of this project is to  determine whether data is positive, negative \\nor neutral. Sentiment analysis is often performed on textual data to help businesses monitor \\nbrand and product sentiment in customer feedback, and understand customer needs. \\n \\n \\nProject Type: Classification Model, Consumer Insights \\nDuration: Dec 2019-Nov 2020 \\nTools Used: Python, Microsoft Power Point \\nTechniques used: SVM Linear, Document Term Matrix, Lexicon Token Analysis, N-gram distribution, \\nSentiment Polarity scoring \\nRole: Project Manager/Data Analyst \\nResponsibilities: \\n\\uf0fc  Requirement Gathering  \\n\\uf0fc  Project Planning and Execution  \\n\\uf0fc  Task Allocation \\n\\uf0fc  Classification modeling \\n\\uf0fc  Feature Engineering \\n\\uf0fc  Python Scripting for Natural Language Processing, Classification \\n\\uf0fc  Power Point Presentation \\n \\nAcademic Qualifications \\n \\n \\n\\uf0b7  SSC  from Shanti Niketan High School with a percentage of 78 %. \\n\\uf0b7  HSC (+2)  in Science(PCM) from Lambodar College of Science with a percentage of  75 %. \\n\\uf0b7  B.Tech from KMBB College of Engineering and Technology with an overall CGPA of 7.01. \\n \\nPersonal Details \\n \\nDate of Birth               :   15th June,1995 \\nGender               :      Male \\nAddress               :      At-Gandhi Nagar Pada,Balangir,odisha,Pin-767001 \\nLinguistics               :     English & Hindi \\nEnd Of Resume'"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Abinash Sahu ---> Label: name\n",
      "Text: +91-7008460530 ---> Label: mobile\n",
      "Text: Python ---> Label: skills\n",
      "Text: Advance Predictive modeling ---> Label: skills\n",
      "Text: Natural Language Processing ---> Label: skills\n",
      "Text: Class|My SQL| Credit Risk Analysis ---> Label: algorithms\n",
      "Text: GIT ---> Label: skills\n",
      "Text: 3+ years ---> Label: total exp\n",
      "Text: Data Science ---> Label: skills\n",
      "Text: Machine Learning ---> Label: skills\n",
      "Text: Linear regression ---> Label: algorithms\n",
      "Text: Logistic regression ---> Label: algorithms\n",
      "Text: Clustering ---> Label: algorithms\n",
      "Text: Decision Trees ---> Label: algorithms\n",
      "Text: Random Forest ---> Label: algorithms\n",
      "Text: Natural \n",
      "Language Processing. ---> Label: skills\n",
      "Text: Python ---> Label: skills\n",
      "Text: data visualization ---> Label: skills\n",
      "Text: data analysis ---> Label: skills\n",
      "Text: Python ---> Label: skills\n",
      "Text: pandas ---> Label: skills\n",
      "Text: numpy ---> Label: skills\n",
      "Text: scikit \n",
      "learn ---> Label: skills\n",
      "Text: Machine Learning ---> Label: skills\n",
      "Text: AI ---> Label: skills\n",
      "Text: ML regression ---> Label: skills\n",
      "Text: classification ---> Label: skills\n",
      "Text: Linear and logistic regression ---> Label: algorithms\n",
      "Text: Decision tree ---> Label: algorithms\n",
      "Text: Random forest ---> Label: algorithms\n",
      "Text: SVM ---> Label: algorithms\n",
      "Text: kNN ---> Label: algorithms\n",
      "Text: Naïve-\n",
      "Bayes ---> Label: algorithms\n",
      "Text: XG-Boost ---> Label: algorithms\n",
      "Text: SQL ---> Label: skills\n",
      "Text: 3+ years ---> Label: total exp\n",
      "Text: Sysark Datasol Pvt. ---> Label: companies\n",
      "Text: Ltd. ---> Label: algorithms\n",
      "Text: Jan 2019 ---> Label: start date\n",
      "Text: Till Date ---> Label: end date\n",
      "Text: Credit Risk Management ---> Label: project name\n",
      "Text: Data Scientist ---> Label: designation\n",
      "Text: Python ---> Label: skills\n",
      "Text: Statistical Analysis ---> Label: skills\n",
      "Text: Machine Learning Models ---> Label: skills\n",
      "Text: Data visualization ---> Label: skills\n",
      "Text: Sentiment Analysis ---> Label: project name\n",
      "Text: Python ---> Label: skills\n",
      "Text: Python ---> Label: skills\n",
      "Text: Microsoft Power Point ---> Label: skills\n",
      "Text: Linear, Document Term Matrix ---> Label: algorithms\n",
      "Text: Lexicon Token Analysis ---> Label: algorithms\n",
      "Text: N-gram distribution ---> Label: algorithms\n",
      "Text: Manager/Data Analyst ---> Label: job roles\n",
      "Text: Python ---> Label: skills\n",
      "Text: Natural Language Processing ---> Label: skills\n",
      "Text: Classification ---> Label: skills\n",
      "Text: Power Point Presentation ---> Label: skills\n",
      "Text: Shanti Niketan High School ---> Label: college name\n",
      "Text: 78 %. ---> Label: percentage\n",
      "Text: HSC (+2)  in Science(PCM) ---> Label: education\n",
      "Text: Lambodar College of Science ---> Label: college name\n",
      "Text: 75 %. ---> Label: percentage\n",
      "Text: B.Tech ---> Label: education\n",
      "Text: KMBB College ---> Label: skills\n",
      "Text: 7.01. ---> Label: percentage\n",
      "Text: 15th ---> Label: education\n",
      "Text: Male \n",
      " ---> Label: skills\n",
      "Text: English ---> Label: linguistics\n",
      "Text: Hindi ---> Label: linguistics\n"
     ]
    }
   ],
   "source": [
    "for ent in doc.ents:\n",
    "    print('Text:',ent.text,'--->','Label:', ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Abinash Sahu ---> Label: name\n",
      "Text: +91-7008460530 ---> Label: mobile\n"
     ]
    }
   ],
   "source": [
    "test1 = \"\"\"Abinash Sahu \n",
    "                                                                     \n",
    " \n",
    "Email ID:abinashgcs@gmail.com                Cell: +91-7008460530 \n",
    " \n",
    "\"\"\"\n",
    "doc1 = nlp(test1)\n",
    "for ent in doc1.ents:\n",
    "    print('Text:',ent.text,'--->','Label:', ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = \"\"\"Highly motivated individual with a strong track record of performance in handling relationship \n",
    "management activities to identify and define business requirements, and translate business needs \n",
    "into complex models. Competent at identifying different data sources and providing associated data \n",
    "modelling and data visualization\"\"\"\n",
    "doc2 = nlp(test2)\n",
    "for ent in doc2.ents:\n",
    "    print('Text:',ent.text,'--->','Label:', ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Python ---> Label: skills\n",
      "Text: Advance Predictive modeling ---> Label: skills\n",
      "Text: Natural Language Processing ---> Label: skills\n",
      "Text: Class|My SQL| Credit Risk Analysis ---> Label: algorithms\n",
      "Text: GIT ---> Label: skills\n"
     ]
    }
   ],
   "source": [
    "test3 = \"\"\"| Python | Advance Predictive modeling and designing drilldown analysis for business insights \n",
    "|Statistical modeling  |Machine Learning Algorithms| EDA | Natural Language Processing |Text \n",
    "mining |Text Class|My SQL| Credit Risk Analysis and Project Management  | Client management \n",
    "and cross functional project handling | GIT  \"\"\"\n",
    "doc3 = nlp(test3)\n",
    "for ent in doc3.ents:\n",
    "    print('Text:',ent.text,'--->','Label:', ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: 3+ years ---> Label: total exp\n",
      "Text: Data Science ---> Label: skills\n",
      "Text: Machine Learning ---> Label: skills\n",
      "Text: Linear regression ---> Label: algorithms\n",
      "Text: Logistic regression ---> Label: algorithms\n",
      "Text: Clustering ---> Label: algorithms\n",
      "Text: Decision Trees ---> Label: algorithms\n",
      "Text: Random Forest ---> Label: algorithms\n",
      "Text: Natural \n",
      "Language Processing. ---> Label: skills\n",
      "Text: Python ---> Label: skills\n",
      "Text: data visualization ---> Label: skills\n",
      "Text: data analysis ---> Label: skills\n"
     ]
    }
   ],
   "source": [
    "test3 = \"\"\"Analytical, enthusiastic and innovative Data Science Lead with  3+ years of IT experience in the \n",
    "different areas of Data Science, Machine Learning and Automation. \n",
    "  Deft at undertaking various statistical methods and testing processes such as hypothesis testing, \n",
    "Linear regression, Logistic regression, Clustering, Decision Trees, Random Forest and Natural \n",
    "Language Processing.  \n",
    " \n",
    "  Pragmatic  exposure  in  data  ingestion  and  cleaning  using  Python  Programming. Thorough \n",
    "knowledge of Data warehousing and Data mining concepts. \n",
    " \n",
    "  Sound knowledge of drawing insights through predictive analysis and data visualization, to drive \n",
    "better decision making through the use of various statistical modelling techniques.  \n",
    " \n",
    "  Experienced in all phases of data analysis spanning definition and analysis of questions with \n",
    "respect to available dasta & resources, overview of data &  assessment of data quality, selection of \n",
    "appropriate models & statistical tests and presentation of results \n",
    " \n",
    "  Leveraging skill in importing, cleaning, transforming, validating or modelling data with the purpose \n",
    "of understanding or making conclusions from the data for decision making purposes. \n",
    " \n",
    "  Good at SQL commands (DDL, DML, DCL, Joins, sub queries) and SQL functions. \"\"\"\n",
    "doc3 = nlp(test3)\n",
    "for ent in doc3.ents:\n",
    "    print('Text:',ent.text,'--->','Label:', ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Python ---> Label: skills\n",
      "Text: pandas ---> Label: skills\n",
      "Text: numpy ---> Label: skills\n",
      "Text: scikit \n",
      "learn ---> Label: skills\n",
      "Text: Machine Learning ---> Label: skills\n",
      "Text: ML regression ---> Label: skills\n",
      "Text: classification ---> Label: skills\n",
      "Text: Linear and logistic regression ---> Label: algorithms\n",
      "Text: Decision tree ---> Label: algorithms\n",
      "Text: Random forest ---> Label: algorithms\n",
      "Text: SVM ---> Label: algorithms\n",
      "Text: kNN ---> Label: algorithms\n",
      "Text: NaÃ¯ve-\n",
      "Bayes ---> Label: algorithms\n",
      "Text: XG-Boost ---> Label: algorithms\n"
     ]
    }
   ],
   "source": [
    "test4 = \"\"\"Python - Developed various regression and classification models of ML using pandas, numpy, scikit \n",
    "learn etc, and visualization using Seaborn and MatPlotlib libraries. Good experience in validating \n",
    "models using Cross validation, confusion matrix, ROC curve etc. \n",
    "  Statistics- Strong understanding on applied Statistics and advance statistical analysis.   Machine Learning and AIâ€“ Strong working knowledge of various ML regression and classification \n",
    "algorithms such as Linear and logistic regression, Decision tree, Random forest, SVM,kNN,NaÃ¯ve-\n",
    "Bayes,XG-Boost etc. Strong knowledge of hypothesis testing. \n",
    "  SQLâ€“ Good knowledge on database management and query writing skills in SQL and Access. \n",
    "Statements and clauses, Entity and attribute relationships, Joins, views, pivot and un-pivot, case and \n",
    "when statement, ranking and row order and store procedures etc. \"\"\"\n",
    "doc4 = nlp(test4)\n",
    "for ent in doc4.ents:\n",
    "    print('Text:',ent.text,'--->','Label:', ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: 3+ years ---> Label: total exp\n",
      "Text: Sysark Datasol Pvt. ---> Label: companies\n",
      "Text: Ltd. ---> Label: algorithms\n",
      "Text: Jan 2019 ---> Label: start date\n",
      "Text: Till Date ---> Label: end date\n",
      "Text: Credit Risk Management ---> Label: project name\n",
      "Text: Data Scientist ---> Label: designation\n",
      "Text: Python ---> Label: skills\n",
      "Text: Statistical Analysis ---> Label: skills\n",
      "Text: Machine Learning Models ---> Label: skills\n",
      "Text: Data visualization ---> Label: skills\n",
      "Text: Sentiment Analysis ---> Label: project name\n",
      "Text: Python ---> Label: skills\n",
      "Text: Python ---> Label: skills\n",
      "Text: Microsoft Power Point ---> Label: skills\n",
      "Text: Linear, Document Term Matrix ---> Label: algorithms\n",
      "Text: Lexicon Token Analysis ---> Label: algorithms\n",
      "Text: N-gram distribution ---> Label: algorithms\n",
      "Text: Manager/Data Analyst ---> Label: job roles\n",
      "Text: Python ---> Label: skills\n",
      "Text: Natural Language Processing ---> Label: skills\n",
      "Text: Classification ---> Label: skills\n",
      "Text: Power Point Presentation ---> Label: skills\n"
     ]
    }
   ],
   "source": [
    "test5 = \"\"\"3+ years of Experience in Sysark Datasol Pvt. Ltd. (Jan 2019-Till Date) \n",
    " \n",
    " \n",
    " Mar 2021 till Sep 2021 \n",
    " \n",
    "Project : Credit Risk Management \n",
    "Designation : Data Scientist  \n",
    "Tools & Techologies used : Python,EDA,Statistical Analysis,Machine Learning Models,Cross Validation. \n",
    "Objective: \n",
    "The main objective of this project is to understand credit risk management which is a practice of mitigating \n",
    "losses by understanding the adequacy of a bankâ€™s capital and loan loss reserves at any given time, a \n",
    "process that has long been a challenge for financial institutions. \n",
    "Effective credit risk management is to gain a complete understanding of a bankâ€™s overall credit risk by \n",
    "viewing risk at the individual, customer and portfolio levels. \n",
    " \n",
    "Responsibility: \n",
    "ï‚·  To understand the Business problem and interact with the client on regular basis to get more and \n",
    "deep insight of the data shared by the client. \n",
    "ï‚·  Better model management that spans the entire modelling life cycle. \n",
    "ï‚·  Data visualization capabilities and business intelligence tools that get important information into \n",
    "the hands of those who need it, when they need it. \n",
    "ï‚·  To draw the insights from the data and develop a predictive model which will help in categorizing \n",
    "the individual customer and sector of the bank efficiently. \n",
    "ï‚·  To do the variable selection which are important in developing predictive model with good \n",
    "accuracy.  \n",
    "ï‚·  Prepare Origination and Performance reporting to create multiple dashboards for drill down \n",
    "analysis and specific KPI metrics. \n",
    "ï‚·  Design data architecture and solve complex data integrity issues.  \n",
    "ï‚·  Design various charts to explain the trend and perforce of portfolios over the period of time. \n",
    "ï‚·  Create drill down analysis in Tableau. \n",
    " \n",
    "      Dec2019-Nov 2020 \n",
    "Project :  Sentiment Analysis \n",
    "Sentiment Analysis for Air Purification Market: The client in consumer electronics domain was looking \n",
    "for insights into a fast growing product in Indian Consumer Market â€“ Air Purifiers. The insights project was \n",
    "driven by Sentiment Analysis of social media data  (i.e. Tweets /Comments / Status Updates/Product \n",
    "reviews) using Python. The project also included a paid review classifier which would flag reviews as paid \n",
    "or genuine. \n",
    "  \n",
    "Objective: The main objective of this project is to  determine whether data is positive, negative \n",
    "or neutral. Sentiment analysis is often performed on textual data to help businesses monitor \n",
    "brand and product sentiment in customer feedback, and understand customer needs. \n",
    " \n",
    " \n",
    "Project Type: Classification Model, Consumer Insights \n",
    "Duration: Dec 2019-Nov 2020 \n",
    "Tools Used: Python, Microsoft Power Point \n",
    "Techniques used: SVM Linear, Document Term Matrix, Lexicon Token Analysis, N-gram distribution, \n",
    "Sentiment Polarity scoring \n",
    "Role: Project Manager/Data Analyst \n",
    "Responsibilities: \n",
    "ïƒ¼  Requirement Gathering  \n",
    "ïƒ¼  Project Planning and Execution  \n",
    "ïƒ¼  Task Allocation \n",
    "ïƒ¼  Classification modeling \n",
    "ïƒ¼  Feature Engineering \n",
    "ïƒ¼  Python Scripting for Natural Language Processing, Classification \n",
    "ïƒ¼  Power Point Presentation \"\"\"\n",
    "\n",
    "doc5 = nlp(test5)\n",
    "for ent in doc5.ents:\n",
    "    print('Text:',ent.text,'--->','Label:', ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Shanti Niketan High School ---> Label: college name\n",
      "Text: 78 %. ---> Label: percentage\n",
      "Text: HSC (+2)  in Science(PCM) ---> Label: education\n",
      "Text: Lambodar College of Science ---> Label: college name\n",
      "Text: 75 %. ---> Label: percentage\n",
      "Text: B.Tech ---> Label: education\n",
      "Text: KMBB College ---> Label: skills\n",
      "Text: 7.01. ---> Label: percentage\n"
     ]
    }
   ],
   "source": [
    "test6 = \"\"\"ï‚·  SSC  from Shanti Niketan High School with a percentage of 78 %. \n",
    "ï‚·  HSC (+2)  in Science(PCM) from Lambodar College of Science with a percentage of  75 %. \n",
    "ï‚·  B.Tech from KMBB College of Engineering and Technology with an overall CGPA of 7.01.\"\"\"\n",
    "doc6 = nlp(test6)\n",
    "for ent in doc6.ents:\n",
    "    print('Text:',ent.text,'--->','Label:', ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: 15th ---> Label: education\n",
      "Text: Male \n",
      " ---> Label: skills\n",
      "Text: English ---> Label: linguistics\n",
      "Text: Hindi ---> Label: linguistics\n"
     ]
    }
   ],
   "source": [
    "test7 = \"\"\"Date of Birth               :   15th June,1995 \n",
    "Gender               :      Male \n",
    "Address               :      At-Gandhi Nagar Pada,Balangir,odisha,Pin-767001 \n",
    "Linguistics               :     English & Hindi\"\"\"\n",
    "\n",
    "doc7 = nlp(test7)\n",
    "for ent in doc7.ents:\n",
    "    print('Text:',ent.text,'--->','Label:', ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('./modelss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = r\"F:\\projects\\RR\\code\\RNER\\testing\\pdf_2_txt\\ManideepGiddam[7_0] (1) (1).txt\"\n",
    "\n",
    "texts = []\n",
    "\n",
    "with open(file, \"r\",encoding='utf-8') as fp:\n",
    "    text = ''.join(fp.readlines())\n",
    "    texts.append(text)\n",
    "\n",
    "content = ''.join(texts)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data scientist designation\n",
      "Data Scientist designation\n",
      "3 years total exp\n",
      "Societe Generale algorithms\n",
      "Machine learning skills\n",
      "Python skills\n",
      "-Python skills\n",
      "Pandas skills\n",
      "Seaborn skills\n",
      "Sk) skills\n",
      "Numpy Pandas designation\n",
      "R skills\n",
      "Senior Analyst job roles\n",
      "Wipro companies\n",
      "HSBC education\n",
      "B. Com education\n",
      "Intermediate project name\n",
      "Sri Chaitanya Jr. college companies\n",
      "S.S.C\n",
      "Hyderabad Sainik School education\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(content)\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
